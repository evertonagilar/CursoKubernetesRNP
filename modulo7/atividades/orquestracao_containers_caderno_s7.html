<!DOCTYPE html>
<html lang="pt_BR">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.17">
<title>Sess√£o 7: Armazenamento no Kubernetes</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
pre.rouge table td { padding: 5px; }
pre.rouge table pre { margin: 0; }
pre.rouge .cm {
  color: #999988;
  font-style: italic;
}
pre.rouge .cp {
  color: #999999;
  font-weight: bold;
}
pre.rouge .c1 {
  color: #999988;
  font-style: italic;
}
pre.rouge .cs {
  color: #999999;
  font-weight: bold;
  font-style: italic;
}
pre.rouge .c, pre.rouge .ch, pre.rouge .cd, pre.rouge .cpf {
  color: #999988;
  font-style: italic;
}
pre.rouge .err {
  color: #a61717;
  background-color: #e3d2d2;
}
pre.rouge .gd {
  color: #000000;
  background-color: #ffdddd;
}
pre.rouge .ge {
  color: #000000;
  font-style: italic;
}
pre.rouge .gr {
  color: #aa0000;
}
pre.rouge .gh {
  color: #999999;
}
pre.rouge .gi {
  color: #000000;
  background-color: #ddffdd;
}
pre.rouge .go {
  color: #888888;
}
pre.rouge .gp {
  color: #555555;
}
pre.rouge .gs {
  font-weight: bold;
}
pre.rouge .gu {
  color: #aaaaaa;
}
pre.rouge .gt {
  color: #aa0000;
}
pre.rouge .kc {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kd {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kn {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kp {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kr {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kt {
  color: #445588;
  font-weight: bold;
}
pre.rouge .k, pre.rouge .kv {
  color: #000000;
  font-weight: bold;
}
pre.rouge .mf {
  color: #009999;
}
pre.rouge .mh {
  color: #009999;
}
pre.rouge .il {
  color: #009999;
}
pre.rouge .mi {
  color: #009999;
}
pre.rouge .mo {
  color: #009999;
}
pre.rouge .m, pre.rouge .mb, pre.rouge .mx {
  color: #009999;
}
pre.rouge .sa {
  color: #000000;
  font-weight: bold;
}
pre.rouge .sb {
  color: #d14;
}
pre.rouge .sc {
  color: #d14;
}
pre.rouge .sd {
  color: #d14;
}
pre.rouge .s2 {
  color: #d14;
}
pre.rouge .se {
  color: #d14;
}
pre.rouge .sh {
  color: #d14;
}
pre.rouge .si {
  color: #d14;
}
pre.rouge .sx {
  color: #d14;
}
pre.rouge .sr {
  color: #009926;
}
pre.rouge .s1 {
  color: #d14;
}
pre.rouge .ss {
  color: #990073;
}
pre.rouge .s, pre.rouge .dl {
  color: #d14;
}
pre.rouge .na {
  color: #008080;
}
pre.rouge .bp {
  color: #999999;
}
pre.rouge .nb {
  color: #0086B3;
}
pre.rouge .nc {
  color: #445588;
  font-weight: bold;
}
pre.rouge .no {
  color: #008080;
}
pre.rouge .nd {
  color: #3c5d5d;
  font-weight: bold;
}
pre.rouge .ni {
  color: #800080;
}
pre.rouge .ne {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nf, pre.rouge .fm {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nl {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nn {
  color: #555555;
}
pre.rouge .nt {
  color: #000080;
}
pre.rouge .vc {
  color: #008080;
}
pre.rouge .vg {
  color: #008080;
}
pre.rouge .vi {
  color: #008080;
}
pre.rouge .nv, pre.rouge .vm {
  color: #008080;
}
pre.rouge .ow {
  color: #000000;
  font-weight: bold;
}
pre.rouge .o {
  color: #000000;
  font-weight: bold;
}
pre.rouge .w {
  color: #bbbbbb;
}
pre.rouge {
  background-color: #f8f8f8;
}
</style>
</head>
<body class="article toc2 toc-left">
<div id="header">
<div id="toc" class="toc2">
<div id="toctitle">√çndice</div>
<ul class="sectlevel1">
<li><a href="#_sess√£o_7_armazenamento_no_kubernetes">Sess√£o 7: Armazenamento no Kubernetes</a>
<ul class="sectlevel2">
<li><a href="#_1_persist√™ncia_de_arquivos">1) Persist√™ncia de arquivos</a></li>
<li><a href="#_2_volumes_persistentes_e_claims">2) Volumes persistentes e <em>claims</em></a></li>
<li><a href="#_3_storage_classes">3) <em>Storage Classes</em></a></li>
<li><a href="#_3_1_provisionamento_manual">3.1) Provisionamento manual</a></li>
<li><a href="#_3_2_provisionamento_din√¢mico">3.2) Provisionamento din√¢mico</a></li>
<li><a href="#_3_3_m√∫ltiplas_utiliza√ß√µes_concorrentes_de_volumes">3.3) M√∫ltiplas utiliza√ß√µes concorrentes de volumes</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="paragraph">
<p><span class="image"><img src="./img/logoRNP.png" alt="logoRNP" width="150" height="60"></span></p>
</div>
<div class="sect1">
<h2 id="_sess√£o_7_armazenamento_no_kubernetes">Sess√£o 7: Armazenamento no Kubernetes</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_1_persist√™ncia_de_arquivos">1) Persist√™ncia de arquivos</h3>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Crie um pod com o nome <code>writer</code>, usando a imagem <code>busybox</code> e executando o comando <code>sleep 3600</code>.</p>
<div class="paragraph">
<p>A seguir, execute um <em>shell</em> interativo no pod e crie o diret√≥rio novo <code>/data</code>. Dentro dele, crie um arquivo com o nome <code>hello</code> e conte√∫do <code>world</code>.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vamos l√°: primeiro, criamos o pod.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl run writer --image=busybox -- sleep 3600</strong>
pod/writer created</pre>
</div>
</div>
<div class="paragraph">
<p>Para criar o arquivo, iremos acessar o pod com um <em>shell</em> interativo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl exec -it writer -- /bin/sh</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Verifique que o contexto foi alterado corretamente:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ # whoami ; hostname</strong>
root
writer</pre>
</div>
</div>
<div class="paragraph">
<p>Note que n√£o existe ainda nenhum diret√≥rio <code>data</code> na raiz do sistema de arquivos. Vamos cri√°-lo.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ # ls</strong>
bin    etc    lib    proc   sys    usr
dev    home   lib64  root   tmp    var</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ # mkdir /data</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Para criar o arquivo <code>hello</code>, basta redirecionar a sa√≠da do comando <code>echo</code>, assim:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ # echo world > /data/hello</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Vejamos se funcionou:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ # cat /data/hello</strong>
world</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Agora, remova o pod <code>writer</code>. O conte√∫do do arquivo <code>/data/hello</code> permanece acess√≠vel?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Antes de remover o pod, devemos sair do <em>shell</em> interativo dentro do pod <code>writer</code>. Verifique que o contexto foi alterado com sucesso.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># whoami ; hostname</strong>
root
s2-master-1</pre>
</div>
</div>
<div class="paragraph">
<p>Agora, remova o pod.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete pod writer</strong>
pod "writer" deleted</pre>
</div>
</div>
<div class="paragraph">
<p>O conte√∫do est√° inacess√≠vel, pois ele n√£o foi armazenado permanentemente em nenhum lugar. De fato, o pod em si n√£o pode ser acessado, uma vez que tenha sido removido.</p>
</div>
</div>
</details>
</li>
<li>
<p>Vamos solucionar isso. Primeiro, crie o diret√≥rio novo <code>/pods</code>.</p>
<div class="paragraph">
<p>A seguir, execute o pod <code>writer</code> com as mesmas configura√ß√µes utilizadas no passo (a), mas desta vez utilizando um volume do tipo <code>HostPath</code> que mapeie o diret√≥rio <code>/pods</code> no <em>node</em> para o diret√≥rio <code>/data</code> no contexto do pod.</p>
</div>
<div class="paragraph">
<p>Finalmente, acesse um <em>shell</em> interativo no pod e crie o arquivo <code>/data/hello</code> com o conte√∫do <code>world</code>, e verifique: o mesmo arquivo existe dentro da pasta <code>/pods</code> no <em>node</em>? Se n√£o, porqu√™?</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Criar o diret√≥rio, evidentemente, √© bastante simples.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># mkdir /pods</strong></pre>
</div>
</div>
<div class="paragraph">
<p>A seguir, criamos o pod <code>writer</code>. Desta vez, como queremos especificar um volume persistente, iremos defini-lo atrav√©s de um arquivo YAML com o conte√∫do que se segue:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">writer</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">busybox</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">writer</span>
    <span class="na">args</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">sleep</span>
    <span class="pi">-</span> <span class="s2">"</span><span class="s">3600"</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/data</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">data-dir</span>
  <span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">data-dir</span>
    <span class="na">hostPath</span><span class="pi">:</span>
      <span class="na">path</span><span class="pi">:</span> <span class="s">/pods</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Crie o pod a partir do arquivo YAML:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f writer.yaml</strong>
pod/writer created</pre>
</div>
</div>
<div class="paragraph">
<p>Agora, acessamos o pod com um <em>shell</em> interativo, como feito anteriormente.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl exec -it writer -- /bin/sh</strong></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ # whoami ; hostname</strong>
root
writer</pre>
</div>
</div>
<div class="paragraph">
<p>Note, desta vez, que a pasta <code>/data</code> j√° foi automaticamente criada pelo sistema&#8201;&#8212;&#8201;afinal, √© sob esta pasta que o volume persistente encontra-se montado.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ # ls -d /data/</strong>
/data/</pre>
</div>
</div>
<div class="paragraph">
<p>Vamos criar o arquivo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ # echo world > /data/hello</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Feito isso, encerre o <em>shell</em> interativo, voltando ao contexto no <em>host</em> <code>s2-master-1</code>. Verifique:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># whoami ; hostname</strong>
root
s2-master-1</pre>
</div>
</div>
<div class="paragraph">
<p>Finalmente, acesse o arquivo criado dentro do pod:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># cat /pods/hello</strong>
cat: /pods/hello: No such file or directory</pre>
</div>
</div>
<div class="paragraph">
<p>U√©&#8230;&#8203; n√£o funcionou? Iremos investigar, a seguir.</p>
</div>
</div>
</details>
</li>
<li>
<p>Onde ter√° ido parar o arquivo? Para isso, √© importante perceber que volumes do tipo <code>hostPath</code> armazenam arquivos na hierarquia de diret√≥rios do <em>node</em> em que o pod est√° executando.</p>
<div class="paragraph">
<p>Sabendo disso, responda: em qual <em>node</em> o pod <code>writer</code> est√° executando?</p>
</div>
<div class="paragraph">
<p>Acesse esse <em>node</em> via SSH e determine se o caminho <code>/pods</code> existe, bem como se o arquivo <code>/pods/hello</code> foi criado e possui o conte√∫do esperado.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Como dito no enunciado, arquivos armazenados em volumes do tipo <code>hostPath</code> s√£o gravados na hierarquia de diret√≥rios do <em>node</em> em que o pod est√° executando. Sabendo disso, fica a pergunta: em que <em>node</em> est√° executando o pod <code>writer</code>?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pod writer -o custom-columns=NAME:.metadata.name,NODE:.spec.nodeName</strong>
NAME     NODE
writer   s2-node-1</pre>
</div>
</div>
<div class="paragraph">
<p>Ah, isso explica tudo! Acesse o <em>node</em> <code>s2-node-1</code> via SSH, via <code>vagrant ssh</code> ou usando o comando que segue:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># sudo -u vagrant ssh -i /home/vagrant/.ssh/tmpkey vagrant@s2-node-1</strong>

(...)

vagrant@s2-node-1:~$</pre>
</div>
</div>
<div class="paragraph">
<p>Uma vez dentro do <em>host</em> <code>s2-node-1</code>, eleve privil√©gio para <code>root</code>&#8230;&#8203;</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>vagrant@s2-node-1:~$ sudo -i</strong></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>root@s2-node-1:~# whoami ; hostname</strong>
root
s2-node-1</pre>
</div>
</div>
<div class="paragraph">
<p>E liste o diret√≥rio <code>/pods</code>. Note que, agora sim, conseguimos visualizar o arquivo criado atrav√©s do pod <code>writer</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>root@s2-node-1:~# ls /pods/</strong>
hello</pre>
</div>
</div>
<div class="paragraph">
<p>E o seu conte√∫do? Ser√° o mesmo?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>root@s2-node-1:~# cat /pods/hello</strong>
world</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Encerre a sess√£o SSH no <em>host</em> <code>s2-node-1</code> antes de prosseguir, garantindo que voc√™ est√° logado na m√°quina <code>s2-master-1</code>, como o usu√°rio <code>root</code>.</p>
<div class="literalblock">
<div class="content">
<pre><strong># whoami ; hostname</strong>
root
s2-master-1</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_2_volumes_persistentes_e_claims">2) Volumes persistentes e <em>claims</em></h3>
<div class="paragraph">
<p>A solu√ß√£o empregada na atividade (1) possui alguns problemas, que iremos atacar em ordem.</p>
</div>
<div class="paragraph">
<p>O primeiro desses problemas √© que o arquivo YAML que define o pod <code>writer</code> possui um grande acoplamento entre a defini√ß√£o dos m√©todos de provisionamento e consumo do <em>storage</em>.</p>
</div>
<div class="paragraph">
<p>Para solucionar isso o Kubernetes prov√™ objetos do tipo <strong>PersistentVolume</strong> (PVs), que podem ser provisionados manualmente por um administrador ou dinamicamente via StorageClasses. PVs s√£o entidades de armazenamento plug√°veis, assim como os volumes que utilizamos na atividade anterior, mas possuem um ciclo de vida independente dos pods que o utilizam.</p>
</div>
<div class="paragraph">
<p>Para utilizar PVs temos objetos do tipo <strong>PersistentVolumeClaim</strong> (PVCs), que consistem em requisi√ß√µes de armazenamento por um usu√°rio. Fazendo um paralelo, assim como pods consomem recursos de <em>nodes</em>, como CPU e mem√≥ria, PVCs consomem recursos de PVs. PVCs podem requisitar especificidades como tamanho a armazenar e tipos de acesso (<code>ReadWriteOnce</code>, <code>ReadOnlyMany</code>, <code>ReadWriteMany</code> ou <code>ReadWriteOncePod</code>).</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Como visto acima, diversos tipos de acesso s√£o suportados por PVs e PVCs: <code>ReadWriteOnce</code>, <code>ReadOnlyMany</code>, <code>ReadWriteMany</code> ou <code>ReadWriteOncePod</code>. Consulte a documenta√ß√£o do Kubernetes e responda: o que significam cada um desses modos? Quais suas abrevia√ß√µes, ao utilizar a linha de comando?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Como documentado em <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes" class="bare">https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes</a> , temos tr√™s modos de acesso poss√≠veis para PVs:</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p><code>ReadWriteOnce</code>: neste modo, o volume pode ser montado como leitura-escrita por um √∫nico <em>node</em>.</p>
</li>
<li>
<p><code>ReadOnlyMany</code>: neste modo, o volume pode ser montado como somente-leitura por m√∫ltiplos <em>nodes</em>.</p>
</li>
<li>
<p><code>ReadWriteMany</code>: neste modo, o volume pode ser montado como leitura-escrita por m√∫ltiplos <em>nodes</em>.</p>
</li>
<li>
<p><code>ReadWriteOncePod</code>: neste modo, o volume pode ser montado como leitura-escrita por um √∫nico pod. Suportado apenas para volumes CSI e Kubernetes vers√µes 1.22 e acima.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Note que a defini√ß√£o dos modos acima especifica que os volumes ser√£o montados por <strong><em>nodes</em></strong>, e n√£o por <strong>pods</strong>. Outro aspecto relevante √© que um volume s√≥ pode ser montado utilizando um desses modos de acesso, mesmo que m√∫ltiplos modos sejam suportados.</p>
</div>
<div class="paragraph">
<p>Quanto √†s abrevia√ß√µes ao utilizar a linha de comando, estas s√£o:</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p><code>RWO</code> : <code>ReadWriteOnce</code></p>
</li>
<li>
<p><code>ROX</code> : <code>ReadOnlyMany</code></p>
</li>
<li>
<p><code>RWX</code> : <code>ReadWriteMany</code></p>
</li>
<li>
<p><code>RWOP</code>: <code>ReadWriteOncePod</code></p>
</li>
</ul>
</div>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Vamos come√ßar pelo PersistentVolume. Crie um PV com o nome <code>pv-data</code> e tipo <code>hostPath</code>, requisitando um espa√ßo de 200Mi e modo de acesso <code>ReadWriteMany</code>. Utilize o mesmo caminho do volume especificado na atividade anterior.</p>
<div class="paragraph">
<p>A seguir, verifique o funcionamento de sua configura√ß√£o com o comando <code>kubectl get pv</code>.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>O arquivo YAML de defini√ß√£o do PV √© relativamente simples, como visto abaixo.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolume</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">pv-data</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">capacity</span><span class="pi">:</span>
    <span class="na">storage</span><span class="pi">:</span> <span class="s">200Mi</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteMany</span>
  <span class="na">hostPath</span><span class="pi">:</span>
    <span class="na">path</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/pods"</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Para cri√°-lo, basta utilizar <code>kubectl apply</code> (ou <code>create</code>).</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f pv-data.yaml</strong>
persistentvolume/pv-data created</pre>
</div>
</div>
<div class="paragraph">
<p>Para visualizar os dados do objeto utilize <code>kubectl get pv</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pv pv-data</strong>
NAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
pv-data   200Mi      RWX            Retain           Available                                   36s</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Agora, para o PersistentVolumeClaim. Crie o PVC <code>pvc-data</code>, com requerimento de armazenamento de 100Mi e modo de acesso <code>ReadWriteOnce</code>.</p>
<div class="paragraph">
<p>A seguir, verifique: quais s√£o os estados do PVC <code>pvc-data</code> e do PV <code>pv-data</code>. Porqu√™?</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>O arquivo YAML que define o PVC √© ainda mais simples que o anterior. Veja:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">pvc-data</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">100Mi</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>A seguir, criamos o objeto&#8230;&#8203;</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f pvc-data.yaml</strong>
persistentvolumeclaim/pvc-data created</pre>
</div>
</div>
<div class="paragraph">
<p>E verificamos seu estado. Note que ele se encontra como <code>Pending</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pvc pvc-data</strong>
NAME       STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
pvc-data   Pending                                                     5s</pre>
</div>
</div>
<div class="paragraph">
<p>O PV, por outro lado, ainda √© marcado como <code>Available</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pv pv-data</strong>
NAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
pv-data   200Mi      RWX            Retain           Available                                   5m24s</pre>
</div>
</div>
<div class="paragraph">
<p>Ao investigar os eventos do PVC, o motivo fica claro: nenhum PV √© identificado como dispon√≠vel para atender os requisitos do PVC. Mas porqu√™?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl describe pvc pvc-data | tail -n1</strong>
  Normal  FailedBinding  9s (x6 over 82s)  persistentvolume-controller  no persistent volumes available for this claim and no storage class is set</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Corrija o problema identificado com o PVC <code>pvc-data</code>.</p>
<div class="paragraph">
<p>A seguir, verifique o estado do PVC <code>pvc-data</code> e do PV <code>pv-data</code> para garantir o funcionamento de sua configura√ß√£o.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>A raz√£o para o erro identificado no passo anterior √© que o PV e o PVC n√£o possuem modos de acesso compat√≠veis: enquanto o PV possui o modo <code>ReadWriteMany</code>, o PVC exige o modo <code>ReadWriteOnce</code>. Para corrigir isso, basta editar o arquivo YAML de defini√ß√£o do PVC:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># sed -i 's/ReadWriteOnce/ReadWriteMany/' pvc-data.yaml</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Agora, delete o objeto e recrie-o.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete pvc pvc-data ; kubectl apply -f pvc-data.yaml</strong>
persistentvolumeclaim "pvc-data" deleted
persistentvolumeclaim/pvc-data created</pre>
</div>
</div>
<div class="paragraph">
<p>Ao visualizar o estado do PVC, imediatamente notamos que ele est√° marcado como <code>Bound</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pvc pvc-data</strong>
NAME       STATUS   VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   AGE
pvc-data   Bound    pv-data   200Mi      RWX                           8s</pre>
</div>
</div>
<div class="paragraph">
<p>Semelhantemente, o PV foi atualizado e agora possui o mesmo estado.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pv pv-data</strong>
NAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM              STORAGECLASS   REASON   AGE
pv-data   200Mi      RWX            Retain           Bound    default/pvc-data                           9m15s</pre>
</div>
</div>
<div class="paragraph">
<p>Note, ainda, que o espa√ßo dispon√≠vel para o PVC <code>pvc-data</code> √© de 200Mi, e n√£o os 100Mi solicitados originalmente. Dado que o PV oferece um espa√ßo maior que o solicitado pelo PVC, o Kubernetes identifica que √© poss√≠vel atender o requisito do <em>claim</em> sem maiores problemas. Se a situa√ß√£o fosse invertida, contudo (isto √©, o PVC solicitando um espa√ßo de armazenamento superior ao que √© disponibilizado pelo PV), a requisi√ß√£o n√£o poderia ser atendida.</p>
</div>
</div>
</details>
</li>
<li>
<p>Fa√ßa com que o pod <code>writer</code> utilize o PVC <code>pvc-data</code> criado no passo anterior, substituindo o volume anteriormente configurado.</p>
<div class="paragraph">
<p>Ap√≥s a recria√ß√£o do pod, crie o arquivo novo <code>/data/pvc-hello</code> com o conte√∫do <code>world</code>, e valide sua presen√ßa no sistema de arquivos do <em>node</em> hospedeiro.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Para fazer a altera√ß√£o solicitada, basta editar a se√ß√£o <code>spec.volumes</code> do arquivo YAML. Seu conte√∫do dever√° ficar assim:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">writer</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">busybox</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">writer</span>
    <span class="na">args</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">sleep</span>
    <span class="pi">-</span> <span class="s2">"</span><span class="s">3600"</span>
    <span class="na">volumeMounts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/data</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">data-dir</span>
  <span class="na">volumes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">data-dir</span>
    <span class="na">persistentVolumeClaim</span><span class="pi">:</span>
      <span class="na">claimName</span><span class="pi">:</span> <span class="s">pvc-data</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Remova o pod, e recrie-o usando o novo arquivo de defini√ß√£o.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete pod writer ; kubectl apply -f writer.yaml</strong>
pod "writer" deleted
pod/writer created</pre>
</div>
</div>
<div class="paragraph">
<p>Agora, utilize o <code>kubectl exec</code> para criar o arquivo solicitado. Veja que podemos realizar essa a√ß√£o sem necessariamente iniciar um <em>shell</em> interativo, com o comando que se segue.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl exec -it writer -- /bin/sh -c 'echo world > /data/pvc-hello'</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Como estabelecido, o pod <code>writer</code> est√° executando no <em>node</em> <code>s2-node-1</code> (devido ao <em>node</em> <code>s2-master-1</code> possuir um <em>taint</em> aplicado, como vimos na sess√£o 3). Para maior agilidade, podemos iniciar uma sess√£o SSH e verificar o conte√∫do do arquivo criado pelo comando anterior em um <em>one-liner</em>. Veja:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># sudo -u vagrant ssh -i /home/vagrant/.ssh/tmpkey vagrant@s2-node-1 cat /pods/pvc-hello</strong>
world</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Considere a pol√≠tica de recupera√ß√£o (<em>Reclaim Policy</em>) do PV <code>pv-data</code>. O que ocorreria com esse PV caso o PVC <code>pvc-data</code> fosse removido?</p>
<div class="paragraph">
<p>Quais outras pol√≠ticas de recupera√ß√£o poderiam ter sido escolhidas?</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>A pol√≠tica de recupera√ß√£o do PV pode ser visualizada com os comandos <code>kubectl get</code> ou <code>kubectl describe</code>. Indo direto ao ponto, podemos usar JSONPath para buscar apenas o campo relevante:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pv pv-data -o custom-columns=NAME:.metadata.name,RECLAIMPOL:.spec.persistentVolumeReclaimPolicy</strong>
NAME      RECLAIMPOL
pv-data   Retain</pre>
</div>
</div>
<div class="paragraph">
<p>Quanto aos demais <em>reclaim policies</em> poss√≠veis, estes est√£o documentados em <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#reclaiming" class="bare">https://kubernetes.io/docs/concepts/storage/persistent-volumes/#reclaiming</a> . Vejamos quais s√£o eles:</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p><strong><em>Retain</em></strong>: este modo permite a recupera√ß√£o manual do recurso. Quanto o PVC √© removido, o PV permanece inalterado e o volume √© marcado como "liberado". Ele ainda n√£o pode ser utilizado por outro <em>claim</em>, contudo, j√° que os dados do <em>claim</em> anterior ainda n√£o foram tratados.</p>
</li>
<li>
<p><strong><em>Delete</em></strong>: neste modo, a dele√ß√£o do PVC ocasiona a remo√ß√£o tamb√©m do PV e do <em>asset</em> de armazenamento em infraestrutura externa suportada, como AWS EBS, GCE PD ou volume Cinder.</p>
</li>
<li>
<p><strong><em>Recycle</em></strong>: neste modo, o sistema realiza uma limpeza b√°sica (<code>rm -rf /${VOLUME}/*</code>) e o marca como dispon√≠vel para outro <em>claim</em>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Vamos testar! Remova o PVC <code>pvc-data</code> e verifique: o que acontece? Porqu√™?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vamos l√°:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete pvc pvc-data</strong>
persistentvolumeclaim "pvc-data" deleted
&lt;HANGUP&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>Ap√≥s esse comando, o PVC fica travado em estado <code>Terminating</code>, e o <em>shell</em> fica indispon√≠vel. Isto ocorre porque o PVC ainda est√° sendo utilizado por um pod ativo (no caso, o pod <code>writer</code>).</p>
</div>
</div>
</details>
</li>
<li>
<p>Encerre o processo de remo√ß√£o do PVC e, a seguir, remova o pod <code>writer</code>. O que acontece com o PVC <code>pvc-data</code> e o PV <code>pv-data</code>?</p>
<div class="paragraph">
<p>Verifique o conte√∫do do diret√≥rio <code>/pods</code> no <em>node</em> hospedeiro: o que aconteceu com os dados armazenados nesse local?</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Para retomar o controle do <em>shell</em>, digite <code>CTRL + C</code>. Em seguida, remova o pod:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete pod writer</strong>
pod "writer" deleted</pre>
</div>
</div>
<div class="paragraph">
<p>Note que o PVC √© removido imediatamente:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pvc pvc-data</strong>
Error from server (NotFound): persistentvolumeclaims "pvc-data" not found</pre>
</div>
</div>
<div class="paragraph">
<p>O PV, por outro lado, fica com o estado <em>Released</em> (liberado)&#8201;&#8212;&#8201;como seria de se esperar para o <em>access mode</em> <code>Retain</code>, explicado anteriormente.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pv pv-data</strong>
NAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM              STORAGECLASS   REASON   AGE
pv-data   200Mi      RWX            Retain           Released   default/pvc-data                           23m</pre>
</div>
</div>
<div class="paragraph">
<p>De fato, os dados escritos pelo pod <code>writer</code> ainda permanecem acess√≠veis no volume persistente, como constatado pelo comando abaixo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># sudo -u vagrant ssh -i /home/vagrant/.ssh/tmpkey vagrant@s2-node-1 cat /pods/pvc-hello</strong>
world</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Antes de prosseguir, remova o PV <code>pv-data</code>.</p>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete pv pv-data</strong>
persistentvolume "pv-data" deleted</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_3_storage_classes">3) <em>Storage Classes</em></h3>
<div class="paragraph">
<p>StorageClasses s√£o formas dos administradores de um <em>cluster</em> Kubernetes descreverem as classes que armazenamento oferecidas pelo ambiente. Essas classes podem mapear n√≠veis de qualidade de servi√ßo, pol√≠ticas de backup, velocidade de acesso ou quaisquer outros atributos arbitr√°rios definidos pelos administradores.</p>
</div>
<div class="paragraph">
<p>Uma funcionalidade interessante provida por StorageClasses √© o fato de que podemos provisionar volumes de forma din√¢mica, isto √©, sob demanda. Sem esse tipo de recurso os administradores devem, primeiro, providenciar volumes manualmente em seus ambiente de <em>storage</em> ou no provedor de <em>cloud</em> e, segundo, criar objetos do tipo PersistentVolume  para represent√°-los no Kubernetes. Com o provisionamento din√¢mico, esses recursos s√£o criados quando solicitados pelo usu√°rio.</p>
</div>
</div>
<div class="sect2">
<h3 id="_3_1_provisionamento_manual">3.1) Provisionamento manual</h3>
<div class="paragraph">
<p>Para melhor ambienta√ß√£o com StorageClasses iremos primeiramente trabalhar com o <em>provisioner</em> <code>Local</code>, que n√£o suporta provisionamento din√¢mico. N√£o obstante, ainda neste caso √© vantajoso trabalhar com StorageClasses em lugar de PVs diretamente, por motivos que veremos nos passo a seguir.</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Antes de criar o StorageClass propriamente dito, √© importante saber que al√©m do seu <em>provisioner</em> (o <em>plugin</em> utilizado para provisionar PVs, como NFS, CephFS, Glusterfs ou AWSElasticBlockStore), um outro par√¢metro a ser definido √© o modo de associa√ß√£o (<em>Volume Binding Mode</em>) a ser utilizado.</p>
<div class="paragraph">
<p>Como estabelecido anteriormente, nesta atividade iremos utilizar o StorageClass com um <em>provisioner</em> do tipo <code>Local</code>. Pesquise na documenta√ß√£o oficial do Kubernetes, e responda: quais <em>Volume Binding Modes</em> s√£o suportados por esse <em>provisioner</em>? O que cada um deles faz?</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Como documentado em <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#volume-binding-mode" class="bare">https://kubernetes.io/docs/concepts/storage/storage-classes/#volume-binding-mode</a> , h√° dois <em>Volume Binding Modes</em> dispon√≠veis: <code>Immediate</code> e <code>WaitForFirstConsumer</code>:</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p><code>Immediate</code>: por padr√£o, este modo indica que o <em>binding</em> do volume ocorrer√° assim que o PVC for criado. Assim, PVs ser√£o associados ou provisionados sem conhecimento dos requerimentos de agendamento de pods. Para <em>backends</em> de armazenamento restritos por topologia ou inacess√≠veis a todos os <em>nodes</em> do <em>cluster</em>, isso pode resultar em pods n√£o-agend√°veis.</p>
</li>
<li>
<p><code>WaitForFirstConsumer</code>: a situa√ß√£o acima pode ser solucionada com o modo <code>WaitForFirstConsumer</code>, que atrasa a associa√ß√£o e cria√ß√£o de PVs at√© que um pod que utilize o PVC seja criado. PVs ser√£o, ent√£o, selecionados ou provisionados considerando a topologia especificada pelos requisitos de agendamento do pod, incluindo aspectos como requerimento de recursos, seletores de <em>nodes</em>, afinidade e anti-afinidade de pods e <em>taints</em> e <em>tolerations</em>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Agora que os <em>Volume Binding Modes</em> v√°lidos para o <em>provisioner</em> <code>Local</code> s√£o conhecidos, vamos ao trabalho.</p>
<div class="paragraph">
<p>Crie um StorageClass com o nome <code>sc-data</code>, <em>provisoner</em> do tipo <code>Local</code> e <em>Volume Binding Mode</em> <code>WaitForFirstConsumer</code>. Verifique o funcionamento de sua configura√ß√£o.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>O arquivo YAMl que define o StorageClass √© bastante simples, e mostrado a seguir.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">storage.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StorageClass</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">sc-data</span>
<span class="na">provisioner</span><span class="pi">:</span> <span class="s">kubernetes.io/no-provisioner</span>
<span class="na">volumeBindingMode</span><span class="pi">:</span> <span class="s">WaitForFirstConsumer</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Crie-o com <code>kubectl apply</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f sc-data.yaml</strong>
storageclass.storage.k8s.io/sc-data created</pre>
</div>
</div>
<div class="paragraph">
<p>E, finalmente, verifique o sucesso na cria√ß√£o do objeto.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get sc</strong>
NAME      PROVISIONER                    RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
sc-data   kubernetes.io/no-provisioner   Delete          WaitForFirstConsumer   false                  3s</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Qual √© a pol√≠tica de recupera√ß√£o (<em>Reclaim Policy</em>) do StorageClass <code>sc-data</code>? Porqu√™?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Esse dado √© mostrado no √∫ltimo comando do passo acima. Podemos tamb√©m buscar o campo espec√≠fico:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get sc sc-data -o custom-columns=NAME:.metadata.name,RECLAIMPOL:.reclaimPolicy</strong>
NAME      RECLAIMPOL
sc-data   Delete</pre>
</div>
</div>
<div class="paragraph">
<p>Como documentado em <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/#reclaim-policy" class="bare">https://kubernetes.io/docs/concepts/storage/storage-classes/#reclaim-policy</a> , PVs dinamicamente criados por um StorageClass ter√£o sua pol√≠tica de recupera√ß√£o atribu√≠da por heran√ßa. Caso nenhuma pol√≠tica seja especificada quando da cria√ß√£o do StorageClass (exatamente o que fizemos, no passo anterior), o <em>reclaim policy</em> assumir√° o valor padr√£o <code>Delete</code>.</p>
</div>
</div>
</details>
</li>
<li>
<p>Como visto anteriormente o StorageClass do tipo <code>Local</code> n√£o suporta provisionamento din√¢mico&#8201;&#8212;&#8201;assim sendo, iremos faz√™-lo manualmente.</p>
<div class="paragraph">
<p>Crie o PV <code>sc-pv-data</code> com tamanho de 250 Mi, modo de acesso <code>ReadWriteOnce</code>, pol√≠tica de recupera√ß√£o <code>Retain</code> e o mesmo caminho usado anteriormente, <code>/pods</code>. Evidentemente, fa√ßa com que esse PV utilize o StorageClass <code>sc-data</code>.</p>
</div>
<div class="paragraph">
<p>Mais um detalhe: algo que foi omitido na atividade anterior, mas que √© bastante relevante, √© que PVs do tipo <code>local</code> devem explicitamente ajustar a afinidade em rela√ß√£o a <em>nodes</em>&#8201;&#8212;&#8201;assim, pods que utilizem esses PVs ser√£o agendados apenas em <em>nodes</em> que podem ser selecionados. Essa caracter√≠sticas n√£o √© t√£o relevante no momento, j√° que nosso <em>cluster</em> possui apenas um <em>node</em> agend√°vel (a m√°quina <code>s2-node-1</code>), mas deve ser considerado em <em>cluster</em> maiores. Essa caracter√≠stica √© documentada neste link: <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#node-affinity" class="bare">https://kubernetes.io/docs/concepts/storage/persistent-volumes/#node-affinity</a></p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>O arquivo YAML que define o PV √© mostrado abaixo. Note o uso do atributo <code>spec.nodeAffinity</code> para garantir o <em>node</em> de agendamento do PV, bem como a customiza√ß√£o do <em>reclaim policy</em> via <code>spec.persistentVolumeReclaimPolicy</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolume</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">sc-pv-data</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">accessModes</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">capacity</span><span class="pi">:</span>
    <span class="na">storage</span><span class="pi">:</span> <span class="s">250Mi</span>
  <span class="na">local</span><span class="pi">:</span>
    <span class="na">path</span><span class="pi">:</span> <span class="s">/pods</span>
  <span class="na">nodeAffinity</span><span class="pi">:</span>
    <span class="na">required</span><span class="pi">:</span>
      <span class="na">nodeSelectorTerms</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">matchExpressions</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">kubernetes.io/hostname</span>
          <span class="na">operator</span><span class="pi">:</span> <span class="s">In</span>
          <span class="na">values</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s">s2-node-1</span>
  <span class="na">persistentVolumeReclaimPolicy</span><span class="pi">:</span> <span class="s">Retain</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">sc-data</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Crie o objeto:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f sc-pv-data.yaml</strong>
persistentvolume/sc-pv-data created</pre>
</div>
</div>
<div class="paragraph">
<p>E verifique o funcionamento de sua configura√ß√£o.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pv</strong>
NAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
sc-pv-data   250Mi      RWO            Retain           Available           sc-data                 4s</pre>
</div>
</div>
<div class="paragraph">
<p>Note que mesmo com o <em>reclaim policy</em> do StorageClass <code>sc-data</code> sendo igual a <code>Delete</code>, conseguimos suplant√°-lo com uma configura√ß√£o espec√≠fica no arquivo YAML que define o PV manualmente provisionado, como objetivado.</p>
</div>
</div>
</details>
</li>
<li>
<p>Perfeito! Agora, crie o PVC <code>sc-pvc-data</code>; utilize as mesmas caracter√≠sticas (<code>accessMode</code> e tamanho de armazenamento) configurados para o PV <code>sc-pv-data</code>. N√£o se esque√ßa de mencionar o uso do StorageClass apropriado.</p>
<div class="paragraph">
<p>Qual √© o estado desse PVC ap√≥s sua cria√ß√£o? Porqu√™?</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vamos l√°:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">sc-pvc-data</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">sc-data</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteOnce</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">250Mi</span></code></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f sc-pvc-data.yaml</strong>
persistentvolumeclaim/sc-pvc-data created</pre>
</div>
</div>
<div class="paragraph">
<p>Note que o estado do PVC, ap√≥s sua cria√ß√£o, √© marcado como <code>Pending</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pvc sc-pvc-data</strong>
NAME          STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
sc-pvc-data   Pending                                      sc-data        30s</pre>
</div>
</div>
<div class="paragraph">
<p>Isto se deve ao uso do <em>volume binding mode</em> <code>WaitForFirstConsumer</code>, atribu√≠do ao StorageClass. De fato, ao observarmos os eventos do PVC, √© exatamente este o motivo pelo qual seu estado √© marcado como pendente: ele est√° aguardando a cria√ß√£o do primeiro consumidor antes de associar-se a um PV.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl describe pvc sc-pvc-data | tail -n1</strong>
  Normal  WaitForFirstConsumer  12s (x15 over 3m30s)  persistentvolume-controller  waiting for first consumer to be created before binding</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Finalmente, recrie o pod <code>writer</code>, desta vez utilizando o PVC <code>sc-pvc-data</code> criado no passo anterior.</p>
<div class="paragraph">
<p>Ap√≥s a cria√ß√£o do pod, crie o arquivo novo <code>/data/sc-pvc-hello</code> com o conte√∫do <code>world</code>, e valide sua presen√ßa no sistema de arquivos do <em>node</em> hospedeiro.</p>
</div>
<div class="paragraph">
<p>Finalmente, verifique: qual o estado do PV <code>sc-pv-data</code>? E quanto ao PVC <code>sc-pvc-data</code>?</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Para criar o pod segundo as especifica√ß√µes, basta editar o nome do PVC utilizado via <code>sed</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># sed -i 's/pvc-data/sc-pvc-data/' writer.yaml</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Em seguida, criamos o pod&#8230;&#8203;</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f writer.yaml</strong>
pod/writer created</pre>
</div>
</div>
<div class="paragraph">
<p>E o arquivo solicitado:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl exec -it writer -- /bin/sh -c 'echo world > /data/sc-pvc-hello'</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Verifique que o arquivo foi, de fato, escrito no volume persistente no <em>node</em> <code>s2-node-1</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># sudo -u vagrant ssh -i /home/vagrant/.ssh/tmpkey vagrant@s2-node-1 cat /pods/sc-pvc-hello</strong>
world</pre>
</div>
</div>
<div class="paragraph">
<p>Uma vez criado o pod, note que o PV √© marcado como <code>Bound</code>, assim como o PVC. Este √© o comportamento esperado ao utilizar o <em>volume binding mode</em> <code>WaitForFirstConsumer</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pv sc-pv-data</strong>
NAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                 STORAGECLASS   REASON   AGE
sc-pv-data   250Mi      RWO            Retain           Bound    default/sc-pvc-data   sc-data                 11m</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pvc</strong>
NAME          STATUS   VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   AGE
sc-pvc-data   Bound    pv-data   250Mi      RWO            sc-data        7m55s</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Antes de partir para a pr√≥xima atividade, remova todos os objetos criados at√© aqui. Iremos arquitetar uma maneira melhor de lidar com a persist√™ncia de dados, a seguir.</p>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete pod writer ; kubectl delete pvc sc-pvc-data ; kubectl delete pv sc-pv-data ; kubectl delete sc sc-data</strong>
pod "writer" deleted
persistentvolumeclaim "sc-pvc-data" deleted
persistentvolume "sc-pv-data" deleted
storageclass.storage.k8s.io "sc-data" deleted</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_3_2_provisionamento_din√¢mico">3.2) Provisionamento din√¢mico</h3>
<div class="paragraph">
<p>Muito embora a configura√ß√£o realizada na atividade anterior tenha funcionado, ela ainda n√£o √© ideal.</p>
</div>
<div class="paragraph">
<p>Imagine, por exemplo, que o pod <code>writer</code> fosse agendado em outro <em>node</em>: o que ocorreria nesse caso? Como o PV foi configurado com afinidade espec√≠fica para o <em>node</em> <code>s2-node-1</code>, o <em>cluster</em> teria problemas em agendar o pod.</p>
</div>
<div class="paragraph">
<p>Considere, ainda, um servi√ßo em que m√∫ltiplos pods precisam ler o mesmo dado&#8201;&#8212;&#8201;como uma pasta compartilhada ou um <em>cluster</em> de banco de dados. Ora, como o armazenamento configurado at√© aqui foi totalmente local, √© f√°cil imaginar que dados escritos em um dos <em>nodes</em> n√£o seria propagado para os demais.</p>
</div>
<div class="paragraph">
<p>Finalmente, note que tivemos que criar manualmente o PV antes que pud√©ssemos associ√°-lo a um PVC, e ent√£o a um pod. Essa configura√ß√£o √© bastante envolvida, e nada pr√°tica.</p>
</div>
<div class="paragraph">
<p>Para resolver essas quest√µes, iremos implementar nesta atividade o provisionamento din√¢mico de PVs. Para garantir que os dados fiquem sincronizados entre os diferentes <em>nodes</em> do <em>cluster</em>, utilizaremos uma solu√ß√£o de armazenamento distru√≠do simples&#8201;&#8212;&#8201;neste caso o <em>Network File System</em> (NFS). Vamos l√°?</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Antes de mais nada, temos que implementar o servidor NFS&#8201;&#8212;&#8201;felizmente, isso √© bastante simples. Iremos criar um servidor NFS na m√°quina <code>s2-master-1</code>, servindo o diret√≥rio <code>/pods</code>.</p>
<div class="paragraph">
<p>Note que esse diret√≥rio foi criado anteriormente, mas nunca foi de fato utilizado porque todos os pods foram agendados no <em>host</em> <code>s2-node-1</code> at√© aqui:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># whoami ; hostname</strong>
root
s2-master-1</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ls -1a /pods</strong>
.
..</pre>
</div>
</div>
<div class="paragraph">
<p>Instale os pacotes necess√°rio ao funcionamento do NFS do lado do servidor:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># apt install -y nfs-kernel-server nfs-common portmap</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Iremos, a seguir, realizar uma configura√ß√£o simples (por√©m insegura) de um servidor NFS para testar o provisionamento din√¢mico de volumes.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Aviso"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Como mencionado, a configura√ß√£o utilizada aqui foi propositalmente simplificada para acelerar a implanta√ß√£o do servi√ßo e focar no tema-alvo da sess√£o, que √© a gest√£o de armazenamento no Kubernetes.</p>
</div>
<div class="paragraph">
<p>A configura√ß√£o detalhada de permissionamento, tanto no n√≠vel do SO, servi√ßo e ambiente de orquestra√ß√£o de containers aumentaria significativamente a complexidade de v√°rios elementos, incluindo os arquivos YAML de defini√ß√£o de objetos, tornando a atividade consideralmente mais complexa. Nesse caso, a atividade provavelmente teria que ser realizada de forma guiada (isto √©, fornecendo ao aluno as perguntas e tamb√©m respostas, juntamente com comandos), alterando a did√°tica utilizada at√© aqui.</p>
</div>
<div class="paragraph">
<p>Em um ambiente de produ√ß√£o, √© cr√≠tico que o permissionamento de diret√≥rios e controle de quais usu√°rios podem ler e escrever arquivos seja cuidadosamente planejado. Assim, ao realizar este tipo de implanta√ß√£o em sua organiza√ß√£o, tenha aten√ß√£o ao fazer os ajustes necess√°rios.</p>
</div>
<div class="paragraph">
<p>Como um desafio, sugere-se que o aluno tente adaptar este roteiro para controlar apropriadamente as permiss√µes de leitura e escrita para os diferentes pods e seus usu√°rios/grupos efetivos. Todos os conhecimentos necess√°rios para este fim j√° foram tratados at√© aqui, neste curso. Voc√™ est√° preparado?</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Vamos l√°. Popule o arquivo <code>/etc/exports</code> com o diret√≥rio que ser√° exportado pelo servidor NFS:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># echo '/pods *(rw,sync,no_subtree_check,no_root_squash,no_all_squash,insecure)' >> /etc/exports</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Atualize a lista de <em>exports</em> do servidor:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># exportfs -rv</strong>
exporting *:/pods</pre>
</div>
</div>
<div class="paragraph">
<p>E verifique seu funcionamento:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># showmount -e</strong>
Export list for s2-master-1:
/pods *</pre>
</div>
</div>
<div class="paragraph">
<p>Perfeito. Vamos agora verificar o funcionamento de nossa configura√ß√£o: acesse o <em>host</em> <code>s2-node-1</code> e veja se ele consegue montar e visualizar o diret√≥rio compartilhado via NFS. Comece efetuando login no <em>host</em>, como o usu√°rio <code>root</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># sudo -u vagrant ssh -i /home/vagrant/.ssh/tmpkey vagrant@s2-node-1</strong>

(...)

vagrant@s2-node-1:~$</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>vagrant@s2-node-1:~$ sudo -i</strong></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>root@s2-node-1:~# hostname ; whoami</strong>
s2-node-1
root</pre>
</div>
</div>
<div class="paragraph">
<p>Teste a montagem do diret√≥rio remoto em qualquer local, por exemplo, na pasta <code>/mnt</code>. Note que utilizaremos o endere√ßo IP do <em>host</em> <code>s2-master-1</code>, e n√£o seu nome de dom√≠nio&#8201;&#8212;&#8201;isto se deve ao fato de que este <em>hostname</em> √© definido atrav√©s do arquivo <code>/etc/hosts</code> no <em>node</em> <code>s2-node-1</code> apenas, e n√£o em um servidor DNS, e √© portanto inv√°lido dentro do contexto de pods criados dentro do <em>cluster</em>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>root@s2-node-1:~# mount -t nfs 192.168.68.20:/pods /mnt</strong></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>root@s2-node-1:~# mount | grep '^192.168.68.20:/pods'</strong>
192.168.68.20:/pods on /mnt type nfs4 (rw,relatime,vers=4.2,rsize=524288,wsize=524288,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=192.168.68.25,local_lock=none,addr=192.168.68.20)</pre>
</div>
</div>
<div class="paragraph">
<p>Tudo certo! Antes de prosseguir, desmonte o diret√≥rio.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>root@s2-node-1:~# umount /mnt</strong></pre>
</div>
</div>
</li>
<li>
<p>Vamos agora realizar a implanta√ß√£o do <em>NFS-Client Provisioner</em> (<a href="https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner" class="bare">https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner</a>), uma solu√ß√£o criada para suportar o provisionamento din√¢mico de PVs no Kubernetes em um servidor NFS preexistente&#8201;&#8212;&#8201;como o que criamos no passo anterior.</p>
<div class="paragraph">
<p>Primeiro, garanta que voc√™ est√° na m√°quina <code>s2-master-1</code>, como usu√°rio <code>root</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># hostname ; whoami</strong>
s2-master-1
root</pre>
</div>
</div>
<div class="paragraph">
<p>Vamos agora criar um ServiceAccount para o servi√ßo de provisionamento, juntamente com um ClusterRole, ClusterRoleBinding, Role e RoleBinding. Observe que o arquivo utilizado no comando a seguir configura o provisionador para funcionamento no namespace <em>default</em>&#8201;&#8212;&#8201;para alterar isso, basta editar o arquivo YAML antes de aplic√°-lo ao <em>cluster</em>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/nfs-subdir-external-provisioner/master/deploy/rbac.yaml</strong>
serviceaccount/nfs-client-provisioner created
clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner created
clusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner created
role.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created
rolebinding.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created</pre>
</div>
</div>
<div class="paragraph">
<p>Vamos verificar o funcionamento do comando:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get clusterrole,clusterrolebinding,role,rolebinding | grep nfs | cut -d' ' -f1</strong>
clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner
clusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner
role.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner
rolebinding.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner</pre>
</div>
</div>
<div class="paragraph">
<p>A seguir criaremos o StorageClass que ir√° consumir o recurso de armazenamento NFS. Usaremos como base o arquivo YAML dispon√≠vel no mesmo GitHub do projeto <em>NFS-Client Provisioner</em>, apenas editando o nome do <em>provisioner</em> para um nome mais em linha com o recurso que configuramos no passo (a).</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl -s https://raw.githubusercontent.com/kubernetes-sigs/nfs-subdir-external-provisioner/master/deploy/class.yaml | \
  sed 's/^\(provisioner:\).&#42;/\1 nfs.contorq.com/' | \
  kubectl apply -f -</strong>
storageclass.storage.k8s.io/nfs-client created</pre>
</div>
</div>
<div class="paragraph">
<p>Verifique o sucesso da configura√ß√£o:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get sc nfs-client</strong>
NAME         PROVISIONER       RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
nfs-client   nfs.contorq.com   Delete          Immediate           false                  66s</pre>
</div>
</div>
<div class="paragraph">
<p>Finalmente, iremos criar o deployment: este ser√° o servi√ßo que efetivamente ir√° monitorar por novos PVCs e criar PVs correspondentes automaticamente, alocando-os dentro do servidor NFS. Novamente, teremos que adaptar o nome do <em>provisioner</em> (assim como feito na cria√ß√£o do StorageClass, acima), bem como o endere√ßo IP do servidor NFS e o caminho exportado por ele.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl -s https://raw.githubusercontent.com/kubernetes-sigs/nfs-subdir-external-provisioner/master/deploy/deployment.yaml | \
  sed '/PROVISIONER_NAME/{n;s/^\([[:space:]]&#42;value:\).&#42;/\1 nfs.contorq.com/;}' | \
  sed '/NFS_SERVER/{n;s/^\([[:space:]]&#42;value:\).&#42;/\1 192.168.68.20/;}' | \
  sed 's/^\([[:space:]]&#42;server:\).&#42;/\1 192.168.68.20/' | \
  sed '/NFS_PATH/{n;s/^\([[:space:]]&#42;value:\).&#42;/\1 \/pods/;}' | \
  sed 's/^\([[:space:]]&#42;path:\).&#42;/\1 \/pods/' | \
  kubectl apply -f -</strong>
deployment.apps/nfs-client-provisioner created</pre>
</div>
</div>
<div class="paragraph">
<p>A seguir, verifique se o deployment, e seu pod correspondente, foram criados.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get deploy,pod</strong>
NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nfs-client-provisioner   1/1     1            1           29s

NAME                                          READY   STATUS    RESTARTS   AGE
pod/nfs-client-provisioner-85f8f98c95-fs8pv   1/1     Running   0          29s</pre>
</div>
</div>
</li>
<li>
<p>Excelente! Hora de testar o ambiente: primeiro, verifique que n√£o existe nenhum PersistentVolume ou PersistentVolumeClaim no ambiente.</p>
<div class="paragraph">
<p>A seguir, crie o PVC <code>dynamic-pvc-data</code> que utilize o StorageClass criado no passo anterior, usando o <code>accessMode</code> <code>ReadWriteMany</code> e tamanho de 500Mi.</p>
</div>
<div class="paragraph">
<p>Finalmente, cheque se o PVC foi criado, bem como um PV correspondente.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vamos verificar a exist√™ncia de PVs e PVCs remanescentes:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pv,pvc</strong>
No resources found</pre>
</div>
</div>
<div class="paragraph">
<p>Agora, para o PVC: utilize o arquivo YAML que se segue.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">dynamic-pvc-data</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">nfs-client</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteMany</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">500Mi</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Crie o objeto com <code>kubectl apply</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f dynamic-pvc-data.yaml</strong>
persistentvolumeclaim/dynamic-pvc-data created</pre>
</div>
</div>
<div class="paragraph">
<p>A seguir, verifique o estado do PVC e seu PV correspondente. Note que o estado do PVC criado √© <em>Bound</em>&#8201;&#8212;&#8201;isto se deve ao <em>volume binding mode</em> utilizado no StorageClass criado no passo anterior, que √© <code>Immediate</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pvc dynamic-pvc-data</strong>
NAME               STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS          AGE
dynamic-pvc-data   Bound    pvc-13a54631-3798-41ba-909d-24ae94e3f262   500Mi      RWX            nfs-client   48s</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pv</strong>
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                      STORAGECLASS          REASON   AGE
pvc-13a54631-3798-41ba-909d-24ae94e3f262   500Mi      RWX            Delete           Bound    default/dynamic-pvc-data   nfs-client            61s</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Agora, recrie o pod <code>writer</code>, desta vez instruindo-o a utilizar o PVC <code>dynamic-pvc-data</code> criado no passo anterior.</p>
<div class="paragraph">
<p>Ap√≥s a cria√ß√£o do pod, crie o arquivo novo <code>/data/dynamic-pvc-hello</code> com o conte√∫do <code>world</code>. Em seguida, responda: onde √© garantida a persist√™ncia desse arquivo? Aponte o local onde o arquivo foi criado, no servidor NFS.</p>
</div>
<div class="paragraph">
<p>Outra pergunta: em qual <em>node</em> foi agendado o pod <code>writer</code>? Em que aspecto isso difere da configura√ß√£o realizada na atividade anterior.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Novamente, para alterar a configura√ß√£o do pod <code>writer</code> basta utilizar o comando <code>sed</code> e editar o nome do PVC em uso.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># sed -i 's/sc-pvc-data/dynamic-pvc-data/' writer.yaml</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Crie o pod e escreva o arquivo solicitado.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f writer.yaml</strong>
pod/writer created</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl exec -it writer -- /bin/sh -c 'echo world > /data/dynamic-pvc-hello'</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Dentro da pasta compartilhada pelo servidor NFS, <code>/pods</code>, note que um diret√≥rio foi criado automaticamente:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ls /pods</strong>
default-dynamic-pvc-data-pvc-13a54631-3798-41ba-909d-24ae94e3f262</pre>
</div>
</div>
<div class="paragraph">
<p>Dentro dele est√° o arquivo criado pelo pod <code>writer</code>, com o conte√∫do que se espera.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># cat /pods/default-dynamic-pvc-data-pvc-13a54631-3798-41ba-909d-24ae94e3f262/dynamic-pvc-hello</strong>
world</pre>
</div>
</div>
<div class="paragraph">
<p>Veja que o pod <code>writer</code> est√° de fato sendo executado pelo <em>node</em> <code>s2-node-1</code>, mas seus dados persistentes est√£o sendo armazenados no servidor NFS <code>s2-master-1</code>. Isto comprova que nossa configura√ß√£o funcionou, e que agora os locais de execu√ß√£o do pod e armazenamento de seus dados s√£o independentes.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pod writer -o custom-columns=NAME:.metadata.name,NODE:.spec.nodeName</strong>
NAME     NODE
writer   s2-node-1</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Finalmente, remova o pod <code>writer</code>. O que acontece com o PVC <code>dynamic-pvc-data</code>? E quanto ao seu PV correspondente?</p>
<div class="paragraph">
<p>A seguir, remova o PVC <code>dynamic-pvc-data</code>. O que acontece com o PV associado? E quanto aos dados armazenados no servidor NFS?</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vamos remover o pod:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete pod writer</strong>
pod "writer" deleted</pre>
</div>
</div>
<div class="paragraph">
<p>Note que o PVC e o PV permanecem no sistema, bem como os dados criados pelo pod.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pvc,pv</strong>
NAME                                     STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS          AGE
persistentvolumeclaim/dynamic-pvc-data   Bound    pvc-13a54631-3798-41ba-909d-24ae94e3f262   500Mi      RWX            nfs-client   4m27s

NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                      STORAGECLASS          REASON   AGE
persistentvolume/pvc-13a54631-3798-41ba-909d-24ae94e3f262   500Mi      RWX            Delete           Bound    default/dynamic-pvc-data   nfs-client            4m27s</pre>
</div>
</div>
<div class="paragraph">
<p>Agora, remova o PVC:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete pvc dynamic-pvc-data</strong>
persistentvolumeclaim "dynamic-pvc-data" deleted</pre>
</div>
</div>
<div class="paragraph">
<p>Como o <em>Reclaim Policy</em> est√° configurado como <code>Delete</code>, o PV tamb√©m √© removido no processo.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pvc,pv</strong>
No resources found</pre>
</div>
</div>
<div class="paragraph">
<p>De igual forma, os dados armazenados no servidor NFS tamb√©m s√£o removidos, quando da exclus√£o do PVC <code>dynamic-pvc-data</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ls /pods</strong></pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>As atividades anteriores resolveram dois dos problemas apontados no motivador desta atividade:</p>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>Agora, n√£o √© mais necess√°rio criar manualmente um PV&#8201;&#8212;&#8201;o provisionamento din√¢mico do StorageClass <code>nfs-client</code> faz com que PVs sejam criados automaticamente assim que um PVC √© solicitado.</p>
</li>
<li>
<p>Adicionalmente, verificamos que mesmo que o pod e o dado n√£o residam no mesmo <em>node</em>, seu agendamento pod e acesso aos dados persistentes √© realizado com sucesso.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Resta, portanto, validar apenas uma quest√£o: ser√° que a solu√ß√£o implementada funciona caso dois pods diferentes precisem ler/escrever no mesmo volume persistente? O atendimento desse requisito √© frequentemente necess√°rio, especialmente em aplica√ß√µes distribu√≠das como <em>clusters</em> de bancos de dados, por exemplo.</p>
</div>
<div class="paragraph">
<p>Vamos verificar! Crie o PVC <code>novel</code> usando o StorageClass <code>nfs-client</code>, com tamanho de 200Mi.</p>
</div>
<div class="paragraph">
<p>A seguir, crie o deployment <code>author</code>, com 2 r√©plicas e usando a imagem <code>busybox</code>, executando o comando <code>sleep 3600</code>. Utilize a estrat√©gia de deployment <code>Recreate</code>. Usando anti-afinidade de pods e <em>tolerations</em>, garanta que os pods desse deployment executem em <em>nodes</em> diferentes do <em>cluster</em>. Finalmente, fa√ßa com que os pods desse deployment montem um volume persistente usando o PVC <code>novel</code> no diret√≥rio <code>/story</code>.</p>
</div>
<div class="paragraph">
<p>Usando um dos pods do deployment <code>author</code>, crie um arquivo novo com qualquer conte√∫do dentro do diret√≥rio <code>/story</code>; a seguir, acesse a outra r√©plica do deployment e verifique que seu conte√∫do est√° acess√≠vel sob o mesmo diret√≥rio.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Uma vez que as r√©plicas do deployment ser√£o executadas em <em>nodes</em> distintos, queremos que o PV provisionado dinamicamente pelo PVC <code>novel</code> seja acessado por todos <em>nodes</em> ao mesmo tempo. Como visto anteriormente, o modo que permite leitura-escrita simult√¢nea nesse caso √© <code>ReadWriteMany</code>.</p>
</div>
<div class="paragraph">
<p>Sabendo disso, crie o PVC com o arquivo YAML que se segue.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">PersistentVolumeClaim</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">novel</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">storageClassName</span><span class="pi">:</span> <span class="s">nfs-client</span>
  <span class="na">accessModes</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ReadWriteMany</span>
  <span class="na">resources</span><span class="pi">:</span>
    <span class="na">requests</span><span class="pi">:</span>
      <span class="na">storage</span><span class="pi">:</span> <span class="s">200Mi</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f novel.yaml</strong>
persistentvolumeclaim/novel created</pre>
</div>
</div>
<div class="paragraph">
<p>Agora, para o deployment. Note o uso de <em>tolerations</em> e anti-afinidade de pods no arquivo YAML abaixo para atingir os objetivos especificados pelo enunciado, bem como a customiza√ß√£o da estrat√©gia do deployment.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">author</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">author</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">2</span>
  <span class="na">strategy</span><span class="pi">:</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">Recreate</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">author</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">tolerations</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s2">"</span><span class="s">node-role.kubernetes.io/control-plane"</span>
        <span class="na">operator</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Exists"</span>
        <span class="na">effect</span><span class="pi">:</span> <span class="s2">"</span><span class="s">NoSchedule"</span>
      <span class="na">affinity</span><span class="pi">:</span>
        <span class="na">podAntiAffinity</span><span class="pi">:</span>
          <span class="na">requiredDuringSchedulingIgnoredDuringExecution</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">labelSelector</span><span class="pi">:</span>
              <span class="na">matchExpressions</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">app</span>
                <span class="na">operator</span><span class="pi">:</span> <span class="s">In</span>
                <span class="na">values</span><span class="pi">:</span>
                <span class="pi">-</span> <span class="s">author</span>
            <span class="na">topologyKey</span><span class="pi">:</span> <span class="s2">"</span><span class="s">kubernetes.io/hostname"</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">author</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">busybox</span>
        <span class="na">args</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s">sleep</span>
        <span class="pi">-</span> <span class="s2">"</span><span class="s">3600"</span>
        <span class="na">volumeMounts</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/story</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">story-dir</span>
      <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">story-dir</span>
        <span class="na">persistentVolumeClaim</span><span class="pi">:</span>
          <span class="na">claimName</span><span class="pi">:</span> <span class="s">novel</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f author.yaml</strong>
deployment.apps/author created</pre>
</div>
</div>
<div class="paragraph">
<p>Verifique o estado do deployment, constatando que os pods est√£o operacionais e executando em <em>nodes</em> distintos.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get deploy author</strong>
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
author   2/2     2            2           103s</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pod -l app=author -o custom-columns=NAME:.metadata.name,NODE:.spec.nodeName</strong>
NAME                      NODE
author-7f85d48844-6qcd6   s2-master-1
author-7f85d48844-998vx   s2-node-1</pre>
</div>
</div>
<div class="paragraph">
<p>Agora criaremos o arquivo <code>/story/chapter1</code> com o conte√∫do <code>Once upon a time&#8230;&#8203;</code> em um dos pods acima:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl exec -it author-7f85d48844-6qcd6 -- /bin/sh -c 'echo "Once upon a time..." > /story/chapter1'</strong></pre>
</div>
</div>
<div class="paragraph">
<p>No outro pod, listamos o diret√≥rio, constatando que o arquivo de fato encontra-se acess√≠vel&#8230;&#8203;</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl exec -it author-7f85d48844-998vx -- /bin/sh -c 'ls /story'</strong>
chapter1</pre>
</div>
</div>
<div class="paragraph">
<p>E que seu conte√∫do √© o mesmo que foi inserido originalmente.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl exec -it author-7f85d48844-998vx -- /bin/sh -c 'cat /story/chapter1'</strong>
Once upon a time...</pre>
</div>
</div>
<div class="paragraph">
<p>Listando a pasta-raiz do compartilhamento NFS, fica claro que um diret√≥rio foi criado para amazenar os dados persistentes, e dentro dele encontra-se o arquivo criado pelo pod.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ls /pods/</strong>
default-novel-pvc-49b725f6-9d5a-4d5a-927a-2e8044e232c3</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># cat /pods/default-novel-pvc-49b725f6-9d5a-4d5a-927a-2e8044e232c3/chapter1</strong>
Once upon a time...</pre>
</div>
</div>
</div>
</details>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_3_3_m√∫ltiplas_utiliza√ß√µes_concorrentes_de_volumes">3.3) M√∫ltiplas utiliza√ß√µes concorrentes de volumes</h3>
<div class="paragraph">
<p>Agora, para um cen√°rio de uso mais complexo. Imagine que v√°rios pods precisam acessar o mesmo PV, como vimos no √∫ltimo passo da atividade anterior, mas que os dados desses pods devem ser individualizados.</p>
</div>
<div class="paragraph">
<p>Voc√™ pode estar se perguntando: em que cen√°rio isso seria necess√°rio?</p>
</div>
<div class="paragraph">
<p>Simples! Suponha, por exemplo, que queremos apontar um analisador de registros de log para um diret√≥rio em que diversos pods escrevem seus eventos. Ora, √© bastante prov√°vel que esses pods escrevam seus registros em arquivos com o mesmo nome (digamos, <code>app.log</code> ou <code>mail.log</code>), ent√£o n√£o faz nenhum sentido&#8201;&#8212;&#8201;e nem sequer √© poss√≠vel&#8201;&#8212;&#8201;que eles sejam criados no mesmo diret√≥rio.</p>
</div>
<div class="paragraph">
<p>Para cen√°rios como esses, <em>subPaths</em> s√£o ideais. Esse atributo permite que um mesmo volume seja utilizado m√∫ltiplas vezes em um √∫nico pod, ou que vari√°veis e express√µes regulares sejam utilizada para customizar o caminho de escrita e leitura em um volume. Vamos testar esse recurso nesta atividade.</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Crie um novo PVC, <code>events</code>, com tamanho de 100Mi. Ele ser√° utilizado para armazenar os eventos gerados por m√∫ltiplos pods.</p>
<div class="paragraph">
<p>A seguir, edite o deployment <code>author</code> e fa√ßa com que o diret√≥rio <code>/log</code> seja montado sob o PV criado no passo anterior. Do ponto de vista do servidor NFS, os arquivos criados por um pod devem ser armazenados dentro do diret√≥rio <code>/pods/${EVENT_PV}/${POD_NAME}</code>, sendo <code>${EVENT_PV}</code> o PersistentVolume criado automaticamente pelo PVC <code>events</code> e <code>${POD_NAME}</code> o <em>hostname</em> do pod em quest√£o.</p>
</div>
<div class="paragraph">
<p>Finalmente, entre em cada um dos pods do deployment e crie um arquivo de eventos no caminho <code>/log/app.log</code> com qualquer conte√∫do. Verifique o funcionamento de sua configura√ß√£o.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>A atividade √© relativamente complexa; vamos l√°. Para criar o PVC <code>events</code>, podemos utilizar o arquivo YAML do PVC <code>novel</code> como base e editar os atributos-chave via <code>sed</code>. Veja:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># cat novel.yaml | sed 's/novel/events/' | sed 's/200/100/' | kubectl apply -f -</strong>
persistentvolumeclaim/events created</pre>
</div>
</div>
<div class="paragraph">
<p>A seguir, edite o deployment <code>author</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl edit deploy author</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Para escrever em um diret√≥rio com o nome do pod, primeiro precisamos determinal qual √© ele&#8201;&#8212;&#8201;felizmente, isso pode ser feito atrav√©s de <em>Downward API environment variables</em>, documentadas em <a href="https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/" class="bare">https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/</a> . Na se√ß√£o <code>.spec.template.spec.containers.env</code>, insira o excerto abaixo.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">env</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">POD_NAME</span>
  <span class="na">valueFrom</span><span class="pi">:</span>
    <span class="na">fieldRef</span><span class="pi">:</span>
      <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
      <span class="na">fieldPath</span><span class="pi">:</span> <span class="s">metadata.name</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Com a vari√°vel <code>${POD_NAME}</code> definida, podemos utiliz√°-la na se√ß√£o <code>.spec.template.spec.containers.volumeMounts</code>, especificando o atributo <code>subPathExpr</code>. Esta funcionalidade √© documentada em <a href="https://kubernetes.io/docs/concepts/storage/volumes/#using-subpath-with-expanded-environment-variables" class="bare">https://kubernetes.io/docs/concepts/storage/volumes/#using-subpath-with-expanded-environment-variables</a> . Utilize o excerto abaixo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">volumeMounts</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/log</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">log-dir</span>
  <span class="na">subPathExpr</span><span class="pi">:</span> <span class="s">$(POD_NAME)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Finalmente, na se√ß√£o <code>.spec.template.spec.volumes</code>, adicione o PVC criado anteriormente.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">volumes</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">log-dir</span>
  <span class="na">persistentVolumeClaim</span><span class="pi">:</span>
    <span class="na">claimName</span><span class="pi">:</span> <span class="s">events</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Saia e salve o arquivo. Os pods do deployment ser√£o encerrados e recriados&#8201;&#8212;&#8201;devido √† estrat√©gia de deployment <code>Recreate</code>. Ap√≥s algum tempo, ambos dever√£o estar ativos:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pod -l app=author</strong>
NAME                      READY   STATUS    RESTARTS   AGE
author-5dbfb76865-p9m2z   1/1     Running   0          35s
author-5dbfb76865-qw7r5   1/1     Running   0          35s</pre>
</div>
</div>
<div class="paragraph">
<p>Entre em cada um dos pods acima e crie o arquivo <code>/log/app.log</code>, com um conte√∫do qualquer.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl exec -it author-5dbfb76865-p9m2z -- /bin/sh -c 'echo event1 > /log/app.log'</strong></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl exec -it author-5dbfb76865-qw7r5 -- /bin/sh -c 'echo event2 > /log/app.log'</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Vamos ver o que aconteceu com o diret√≥rio compartilhado via NFS.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ls /pods</strong>
default-events-pvc-2bf969eb-d07e-4a6c-b9a0-1c0c979d6632
default-novel-pvc-49b725f6-9d5a-4d5a-927a-2e8044e232c3</pre>
</div>
</div>
<div class="paragraph">
<p>Temos a nova pasta <code>default-events-pvc-2bf969eb-d07e-4a6c-b9a0-1c0c979d6632</code>, que referencia o PVC <code>events</code>. Dentro dela, foram criadas duas pastas&#8201;&#8212;&#8201;com o nome dos pods pertencentes ao deployment <code>author</code>, como esperar√≠amos.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ls -1 /pods/default-events-pvc-2bf969eb-d07e-4a6c-b9a0-1c0c979d6632/</strong>
author-5dbfb76865-p9m2z
author-5dbfb76865-qw7r5</pre>
</div>
</div>
<div class="paragraph">
<p>Listando recursivamente esse diret√≥rio, notamos que cada um desses diret√≥rios possui um arquivo <code>app.log</code> dentro de si.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ls -R /pods/default-events-pvc-2bf969eb-d07e-4a6c-b9a0-1c0c979d6632/</strong>
/pods/default-events-pvc-2bf969eb-d07e-4a6c-b9a0-1c0c979d6632/:
author-5dbfb76865-p9m2z  author-5dbfb76865-qw7r5

/pods/default-events-pvc-2bf969eb-d07e-4a6c-b9a0-1c0c979d6632/author-5dbfb76865-p9m2z:
app.log

/pods/default-events-pvc-2bf969eb-d07e-4a6c-b9a0-1c0c979d6632/author-5dbfb76865-qw7r5:
app.log</pre>
</div>
</div>
<div class="paragraph">
<p>Usando um <em>loop</em> <code>for</code> combinado com o comando <code>find</code>, √© trivial imprimir o conte√∫do desses arquivos na tela e constatar que seu conte√∫do √© o mesmo que foi inserido dentro do contexto dos pods.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># for file in $( find /pods/default-events-pvc-2bf969eb-d07e-4a6c-b9a0-1c0c979d6632/ -type f -print ); do echo -e "\n$file\n$( cat $file )"; done</strong>

/pods/default-events-pvc-2bf969eb-d07e-4a6c-b9a0-1c0c979d6632/author-5dbfb76865-qw7r5/app.log
event2

/pods/default-events-pvc-2bf969eb-d07e-4a6c-b9a0-1c0c979d6632/author-5dbfb76865-p9m2z/app.log
event1</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Finalmente, remova todos os objetos criados nesta sess√£o para liberar recursos do <em>cluster</em>:</p>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete deploy,pvc,pv --all</strong>
deployment.apps "author" deleted
deployment.apps "nfs-client-provisioner" deleted
persistentvolumeclaim "events" deleted
persistentvolumeclaim "novel" deleted
persistentvolume "pvc-2bf969eb-d07e-4a6c-b9a0-1c0c979d6632" deleted
persistentvolume "pvc-49b725f6-9d5a-4d5a-927a-2e8044e232c3" deleted</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete sc --all</strong>
storageclass.storage.k8s.io "nfs-client" deleted</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete role leader-locking-nfs-client-provisioner ; kubectl delete rolebindings.rbac.authorization.k8s.io leader-locking-nfs-client-provisioner</strong>
role.rbac.authorization.k8s.io "leader-locking-nfs-client-provisioner" deleted
rolebinding.rbac.authorization.k8s.io "leader-locking-nfs-client-provisioner" deleted</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete clusterrole nfs-client-provisioner-runner ; kubectl delete clusterrolebinding run-nfs-client-provisioner</strong>
clusterrole.rbac.authorization.k8s.io "nfs-client-provisioner-runner" deleted
clusterrolebinding.rbac.authorization.k8s.io "run-nfs-client-provisioner" deleted</pre>
</div>
</div>
</li>
</ol>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Aviso"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>ENTREGA DA TAREFA</strong></p>
</div>
<div class="paragraph">
<p>Para que seja considerada entregue voc√™ deve anexar a esta atividade no AVA uma imagem (nos formatos .png ou .jpg) do terminal com a sa√≠da do comando <code>ls</code> que mostra que dos arquivos <code>app.log</code> <strong>diferentes</strong> foram criados em pastas nos diret√≥rios <code>/pods/*events*/author*</code>. Isto ir√° comprovar o funcionamento da utiliza√ß√£o concorrente de volumes no <em>cluster</em>.</p>
</div>
<div class="paragraph">
<p>Utilize como refer√™ncia a sa√≠da de comando mostrada na atividade 7.3.3 (a) deste roteiro.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
√öltima atualiza√ß√£o 2023-06-24 10:08:40 -0300
</div>
</div>
</body>
</html>
