<!DOCTYPE html>
<html lang="pt_BR">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.17">
<title>Sessão 8: Redes no Kubernetes</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
pre.rouge table td { padding: 5px; }
pre.rouge table pre { margin: 0; }
pre.rouge .cm {
  color: #999988;
  font-style: italic;
}
pre.rouge .cp {
  color: #999999;
  font-weight: bold;
}
pre.rouge .c1 {
  color: #999988;
  font-style: italic;
}
pre.rouge .cs {
  color: #999999;
  font-weight: bold;
  font-style: italic;
}
pre.rouge .c, pre.rouge .ch, pre.rouge .cd, pre.rouge .cpf {
  color: #999988;
  font-style: italic;
}
pre.rouge .err {
  color: #a61717;
  background-color: #e3d2d2;
}
pre.rouge .gd {
  color: #000000;
  background-color: #ffdddd;
}
pre.rouge .ge {
  color: #000000;
  font-style: italic;
}
pre.rouge .gr {
  color: #aa0000;
}
pre.rouge .gh {
  color: #999999;
}
pre.rouge .gi {
  color: #000000;
  background-color: #ddffdd;
}
pre.rouge .go {
  color: #888888;
}
pre.rouge .gp {
  color: #555555;
}
pre.rouge .gs {
  font-weight: bold;
}
pre.rouge .gu {
  color: #aaaaaa;
}
pre.rouge .gt {
  color: #aa0000;
}
pre.rouge .kc {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kd {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kn {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kp {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kr {
  color: #000000;
  font-weight: bold;
}
pre.rouge .kt {
  color: #445588;
  font-weight: bold;
}
pre.rouge .k, pre.rouge .kv {
  color: #000000;
  font-weight: bold;
}
pre.rouge .mf {
  color: #009999;
}
pre.rouge .mh {
  color: #009999;
}
pre.rouge .il {
  color: #009999;
}
pre.rouge .mi {
  color: #009999;
}
pre.rouge .mo {
  color: #009999;
}
pre.rouge .m, pre.rouge .mb, pre.rouge .mx {
  color: #009999;
}
pre.rouge .sa {
  color: #000000;
  font-weight: bold;
}
pre.rouge .sb {
  color: #d14;
}
pre.rouge .sc {
  color: #d14;
}
pre.rouge .sd {
  color: #d14;
}
pre.rouge .s2 {
  color: #d14;
}
pre.rouge .se {
  color: #d14;
}
pre.rouge .sh {
  color: #d14;
}
pre.rouge .si {
  color: #d14;
}
pre.rouge .sx {
  color: #d14;
}
pre.rouge .sr {
  color: #009926;
}
pre.rouge .s1 {
  color: #d14;
}
pre.rouge .ss {
  color: #990073;
}
pre.rouge .s, pre.rouge .dl {
  color: #d14;
}
pre.rouge .na {
  color: #008080;
}
pre.rouge .bp {
  color: #999999;
}
pre.rouge .nb {
  color: #0086B3;
}
pre.rouge .nc {
  color: #445588;
  font-weight: bold;
}
pre.rouge .no {
  color: #008080;
}
pre.rouge .nd {
  color: #3c5d5d;
  font-weight: bold;
}
pre.rouge .ni {
  color: #800080;
}
pre.rouge .ne {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nf, pre.rouge .fm {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nl {
  color: #990000;
  font-weight: bold;
}
pre.rouge .nn {
  color: #555555;
}
pre.rouge .nt {
  color: #000080;
}
pre.rouge .vc {
  color: #008080;
}
pre.rouge .vg {
  color: #008080;
}
pre.rouge .vi {
  color: #008080;
}
pre.rouge .nv, pre.rouge .vm {
  color: #008080;
}
pre.rouge .ow {
  color: #000000;
  font-weight: bold;
}
pre.rouge .o {
  color: #000000;
  font-weight: bold;
}
pre.rouge .w {
  color: #bbbbbb;
}
pre.rouge {
  background-color: #f8f8f8;
}
</style>
</head>
<body class="article toc2 toc-left">
<div id="header">
<div id="toc" class="toc2">
<div id="toctitle">Índice</div>
<ul class="sectlevel1">
<li><a href="#_sessão_8_redes_no_kubernetes">Sessão 8: Redes no Kubernetes</a>
<ul class="sectlevel2">
<li><a href="#_1_container_network_interface_cni">1) Container Network Interface (CNI)</a></li>
<li><a href="#_2_deployment_da_solução_de_rede">2) Deployment da solução de rede</a></li>
<li><a href="#_3_calico">3) Calico</a></li>
<li><a href="#_4_redes_de_serviços">4) Redes de serviços</a></li>
<li><a href="#_5_coredns">5) CoreDNS</a></li>
<li><a href="#_6_ingress">6) Ingress</a></li>
<li><a href="#_6_1_ingress_controller">6.1) Ingress Controller</a></li>
<li><a href="#_6_2_ingress_via_http">6.2) Ingress via HTTP</a></li>
<li><a href="#_6_3_ingress_via_https">6.3) Ingress via HTTPS</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="paragraph">
<p><span class="image"><img src="./img/logoRNP.png" alt="logoRNP" width="150" height="60"></span></p>
</div>
<div class="sect1">
<h2 id="_sessão_8_redes_no_kubernetes">Sessão 8: Redes no Kubernetes</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_1_container_network_interface_cni">1) Container Network Interface (CNI)</h3>
<div class="paragraph">
<p>O <em>Container Network Interface</em> (CNI) é uma especificação e conjunto de bibliotecas para escrever plugins que configuram a rede em containers. Os plugins CNI são responsáveis por configurar o gerenciamento de redes no Kubernetes e implementar o modelo de rede do Kubernetes.</p>
</div>
<div class="paragraph">
<p>Nesta atividade, você vai explorar onde os plugins CNI estão localizados no sistema, identificar o plugin CNI em uso e examinar os arquivos de configuração associados a esse plugin.</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Tudo começa pela configuração do <em>Container Runtime Interface</em> (CRI) em uso, o <code>containerd</code> em nosso caso. Analise o arquivo <code>/etc/containerd/config.toml</code>, procurando pela definição do plugin CNI na seção <code>[plugins."io.containerd.grpc.v1.cri".cni]</code>, e responda: onde ficam a configuração dos plugins CNI utilizados neste sistema? E seus binários?</p>
<div class="paragraph">
<p>Finalmente, responda: qual plugin CNI está sendo utilizado pelo <em>cluster</em>?</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>O comando abaixo pode ser usado para mostrar a seção específica do arquivo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># grep 'plugins."io.containerd.grpc.v1.cri".cni' /etc/containerd/config.toml -A5</strong>
    [plugins."io.containerd.grpc.v1.cri".cni]
      bin_dir = "/opt/cni/bin"
      conf_dir = "/etc/cni/net.d"
      conf_template = ""
      ip_pref = ""
      max_conf_num = 1</pre>
</div>
</div>
<div class="paragraph">
<p>Como visto acima, os binários dos <em>plugins</em> CNI ficam no diretório <code>/opt/cni/bin</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ls /opt/cni/bin/</strong>
bandwidth
bridge
calico
calico-ipam
dhcp
dummy
firewall
flannel
host-device
host-local
install
ipvlan
loopback
macvlan
portmap
ptp
sbr
static
tuning
vlan
vrf</pre>
</div>
</div>
<div class="paragraph">
<p>As configurações, por outro lado, ficam no diretório <code>/etc/cni/net.d</code>. Vamos listá-lo.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ls /etc/cni/net.d/</strong>
10-calico.conflist  calico-kubeconfig</pre>
</div>
</div>
<div class="paragraph">
<p>Podemos intuir, portanto, que o plugin CNI em uso é o Calico.</p>
</div>
</div>
</details>
</li>
<li>
<p>Observe o arquivo de configuração do plugin CNI em uso. Você poderia explicar a função dos principais parâmetros nesse arquivo?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>O arquivo de configuração do Calico, localizado em <code>/etc/cni/net.d/10-calico.conflist</code>, contém as informações necessárias para configurar a rede dos pods utilizando o plugin Calico. Vamos vê-lo na íntegra:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="json"><span class="p">{</span><span class="w">
  </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"k8s-pod-network"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"cniVersion"</span><span class="p">:</span><span class="w"> </span><span class="s2">"0.3.1"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"plugins"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"calico"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"log_level"</span><span class="p">:</span><span class="w"> </span><span class="s2">"info"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"log_file_path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/var/log/calico/cni/cni.log"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"datastore_type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"kubernetes"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"nodename"</span><span class="p">:</span><span class="w"> </span><span class="s2">"s2-master-1"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"mtu"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
      </span><span class="nl">"ipam"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"calico-ipam"</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="nl">"policy"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"k8s"</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="nl">"kubernetes"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
          </span><span class="nl">"kubeconfig"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/etc/cni/net.d/calico-kubeconfig"</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"portmap"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"snat"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w">
      </span><span class="nl">"capabilities"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nl">"portMappings"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">}</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"bandwidth"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"capabilities"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nl">"bandwidth"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Suas principais opções incluem:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>type</code>: <code>calico</code> &#8594; Especifica que o plugin Calico será utilizado.</p>
</li>
<li>
<p><code>log_level</code>: <code>info</code> e <code>log_file_path</code>: <code>/var/log/calico/cni/cni.log</code> &#8594; Configura o nível de log e o caminho do arquivo de log.</p>
</li>
<li>
<p><code>datastore_type": `kubernetes</code> &#8594; Define o tipo de armazenamento de dados como <code>kubernetes</code>. Este parâmetro também pode ser configurado como <code>etcd</code>, algo especialmente indicado para <em>clusters</em> de maior porte (ref. <a href="https://docs.tigera.io/calico/latest/getting-started/kubernetes/hardway/the-calico-datastore" class="bare">https://docs.tigera.io/calico/latest/getting-started/kubernetes/hardway/the-calico-datastore</a>).</p>
</li>
<li>
<p><code>nodename</code>: <code>s2-master-1</code> &#8594; Nome do nó onde o plugin está sendo executado, ou o <em>host</em> local, em outras palavras.</p>
</li>
<li>
<p><code>ipam</code>: { <code>type</code>: <code>calico-ipam</code> } &#8594; Define como o gerenciamento de endereços IP será realizado, neste caso usando o Calico IPAM.</p>
</li>
<li>
<p><code>kubernetes</code>: { <code>kubeconfig</code>: <code>/etc/cni/net.d/calico-kubeconfig</code> }: Especifica o caminho do arquivo <code>kubeconfig</code> para o plugin Calico.</p>
</li>
</ul>
</div>
</div>
</details>
</li>
<li>
<p>Qual a utilidade do atributo <code>.plugins.kubernetes.kubeconfig</code> no arquivo de configuração analisado no item anterior?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>O arquivo <code>/etc/cni/net.d/calico-kubeconfig</code> é o arquivo <code>kubeconfig</code> específico para o plugin Calico. Vamos visualizar uma versão resumida deste:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Config</span>
<span class="na">clusters</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">local</span>
  <span class="na">cluster</span><span class="pi">:</span>
    <span class="na">server</span><span class="pi">:</span> <span class="s">https://10.96.0.1:443</span>
    <span class="na">certificate-authority-data</span><span class="pi">:</span> <span class="s">${CERTIFICATE_AUTHORITY_DATA}</span>
<span class="na">users</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">calico</span>
  <span class="na">user</span><span class="pi">:</span>
    <span class="na">token</span><span class="pi">:</span> <span class="s">${TOKEN}</span>
<span class="na">contexts</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">calico-context</span>
  <span class="na">context</span><span class="pi">:</span>
    <span class="na">cluster</span><span class="pi">:</span> <span class="s">local</span>
    <span class="na">user</span><span class="pi">:</span> <span class="s">calico</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Ele é necessário para que ele possa se comunicar com a API do Kubernetes, autenticar-se e acessar os recursos necessários para configurar a rede dos pods. O arquivo <code>kubeconfig</code> contém informações como o endpoint da API do Kubernetes, o <em>token</em> de autenticação e os dados do certificado de autoridade (CA) para validar a conexão com a API.</p>
</div>
</div>
</details>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_2_deployment_da_solução_de_rede">2) Deployment da solução de rede</h3>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Antes de iniciar, execute o seguinte comando:</p>
<div class="literalblock">
<div class="content">
<pre><strong># lab-8.2.1</strong></pre>
</div>
</div>
</li>
<li>
<p>A seguir, crie o pod <code>web</code> usando a imagem <code>nginx:alpine</code>. O que ocorre? Porquê?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Primeiro, criamos o pod:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl run web --image=nginx:alpine</strong>
pod/web created</pre>
</div>
</div>
<div class="paragraph">
<p>Verificando seu estado, veja que ele permance como <code>ContainerCreating</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pod web</strong>
NAME   READY   STATUS              RESTARTS   AGE
web    0/1     ContainerCreating   0          29s</pre>
</div>
</div>
<div class="paragraph">
<p>A seção <code>Events</code> do <code>kubectl describe</code> mostra o motivo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl describe pod web | tail -n3</strong>
  Normal   Scheduled               7m9s                  default-scheduler  Successfully assigned default/web to s2-node-1
  Warning  FailedCreatePodSandBox  7m10s                 kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = [failed to set up sandbox container "73fa18d98918a65de910971e457f9b9cc5726d72ecd116a559b10e03030bc6fc" network for pod "web": networkPlugin cni failed to set up pod "web_default" network: plugin type="calico" failed (add): error getting ClusterInformation: connection is unauthorized: Unauthorized, failed to clean up sandbox container "73fa18d98918a65de910971e457f9b9cc5726d72ecd116a559b10e03030bc6fc" network for pod "web": networkPlugin cni failed to teardown pod "web_default" network: plugin type="calico" failed (delete): error getting ClusterInformation: connection is unauthorized: Unauthorized]
  Normal   SandboxChanged          118s (x26 over 7m9s)  kubelet            Pod sandbox changed, it will be killed and re-created.</pre>
</div>
</div>
<div class="paragraph">
<p>O erro apontado, <code>networkPlugin cni failed to set up pod</code> significa que o pod não pôde ser criado em razão de falha no provisionamento de rede para o mesmo.</p>
</div>
<div class="paragraph">
<p>Qual será o motivo desse erro? Vamos investigar.</p>
</div>
</div>
</details>
</li>
<li>
<p>Inspecione os pods do namespace <code>kube-system</code> e responda: qual poderia ser o motivo do erro observado no passo anterior?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Busque a lista de pods do namespace em questão:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system get pod -o name</strong>
pod/coredns-5d78c9869d-bfdfr
pod/coredns-5d78c9869d-vzvgp
pod/etcd-s2-master-1
pod/kube-apiserver-s2-master-1
pod/kube-controller-manager-s2-master-1
pod/kube-proxy-fc2q9
pod/kube-proxy-jqwmb
pod/kube-scheduler-s2-master-1
pod/metrics-server-774bbc9d75-s56t6</pre>
</div>
</div>
<div class="paragraph">
<p>Note que não há nenhum pod relacionado à configuração de rede em pods (como <code>calico</code>, <code>cilium</code> ou <code>flannel</code>, para citar alguns). De fato, basta comparar a saída desse comando com a de outros capítulos, em que também invocamos o comando <code>kubectl get pod</code> no namespace <code>kube-system</code>, para constatar que os pods em questão estão faltando.</p>
</div>
</div>
</details>
</li>
<li>
<p>Faça o deployment da solução de rede Calico no <em>cluster</em>, e verifique se o problema é contornado.</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Segundo as instruções em <a href="https://docs.tigera.io/calico/latest/getting-started/kubernetes/self-managed-onprem/onpremises" class="bare">https://docs.tigera.io/calico/latest/getting-started/kubernetes/self-managed-onprem/onpremises</a> (aba <em>Manifest</em>) , a instalação do Calico é bastante fácil. Veja:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/calico.yaml | kubectl apply -f -</strong>
poddisruptionbudget.policy/calico-kube-controllers created
serviceaccount/calico-kube-controllers created
serviceaccount/calico-node created
configmap/calico-config created
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created
clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrole.rbac.authorization.k8s.io/calico-node created
clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrolebinding.rbac.authorization.k8s.io/calico-node created
daemonset.apps/calico-node created
deployment.apps/calico-kube-controllers created</pre>
</div>
</div>
<div class="paragraph">
<p>O comando acima configura todos os aspectos de autorização, DaemonSet e deployment responsáveis pela operação do Calico no <em>cluster</em>. Após algum tempo, os pods estão operacionais:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system get pod -l 'k8s-app in (calico-node,calico-kube-controllers)'</strong>
NAME                                       READY   STATUS    RESTARTS   AGE
calico-kube-controllers-674fff74c8-krrng   1/1     Running   0          3m43s
calico-node-9xsv5                          1/1     Running   0          3m43s
calico-node-rtqfd                          1/1     Running   0          3m43s</pre>
</div>
</div>
<div class="paragraph">
<p>E, de igual forma, o pod <code>web</code> criado anteriormente também é disponibilizado.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pod web</strong>
NAME   READY   STATUS    RESTARTS   AGE
web    1/1     Running   0          8m54s</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Antes de continuar, remova o pod <code>web</code>.</p>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete pod web</strong>
pod "web" deleted</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_3_calico">3) Calico</h3>
<div class="sect3">
<h4 id="_3_1_determinando_informações_gerais">3.1) Determinando informações gerais</h4>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>O Calico possui alguns componentes operando no <em>namespace</em> <code>kube-system</code>. Quais são eles, e em quais <em>nodes</em> do <em>cluster</em> eles operam?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vamos ver o que está executando sob o nome <code>calico</code> no <em>namespace</em> <code>kube-system</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system get all | grep calico</strong>
pod/calico-kube-controllers-674fff74c8-wrc52   1/1     Running   1 (15h ago)      15h
pod/calico-node-dpgw2                          1/1     Running   1 (15h ago)      15h
pod/calico-node-r627r                          1/1     Running   1 (15h ago)      15h
daemonset.apps/calico-node   2         2         2       2            2           kubernetes.io/os=linux   15h
deployment.apps/calico-kube-controllers   1/1     1            1           15h
replicaset.apps/calico-kube-controllers-674fff74c8   1         1         1       15h</pre>
</div>
</div>
<div class="paragraph">
<p>Temos, portanto, um deployment de nome <code>calico-kube-controllers</code> e um DaemonSet de nome <code>calico-node</code>. Vamos ver em que <em>nodes</em> cada um desses pods opera. Podemos usar seus <em>labels</em> para filtragem, como mostrado abaixo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system get pod -l k8s-app=calico-kube-controllers -o wide</strong>
NAME                                       READY   STATUS    RESTARTS      AGE   IP              NODE        NOMINATED NODE   READINESS GATES
calico-kube-controllers-674fff74c8-wrc52   1/1     Running   1 (15h ago)   15h   10.41.181.133   s2-node-1   &lt;none&gt;           &lt;none&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>Note que o <code>calico-kube-controllers</code> opera no <em>control plane</em> do <em>cluster</em>, no <em>node</em> <code>s2-master-1</code>. E quanto ao DaemonSet <code>calico-node</code>?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system get pod -l k8s-app=calico-node -o wide</strong>
NAME                READY   STATUS    RESTARTS      AGE   IP              NODE          NOMINATED NODE   READINESS GATES
calico-node-dpgw2   1/1     Running   1 (15h ago)   15h   192.168.68.25   s2-node-1     &lt;none&gt;           &lt;none&gt;
calico-node-r627r   1/1     Running   1 (15h ago)   15h   192.168.68.20   s2-master-1   &lt;none&gt;           &lt;none&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>Como era de se imaginar, ele possui uma cópia de cada pod operando em um <em>node</em> do <em>cluster</em>.</p>
</div>
</div>
</details>
</li>
<li>
<p>Qual a função do deployment <code>calico-kube-controllers</code> no <em>cluster</em>? Quais seus componentes?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>O deployment <code>calico-kube-controllers</code> é responsável por executar os controladores do Calico necessários para gerenciar corretamente o tráfego de rede, as políticas de rede e a conectividade entre os pods no <em>cluster</em> Kubernetes. Os controladores são principalmente configurados por meio de variáveis de ambiente, que são definidas na seção <code>env</code> do documento de definição do pod.</p>
</div>
<div class="paragraph">
<p>O container <code>calico-kube-controllers</code> inclui os seguintes controladores:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Controlador de política (<em>policy controller</em>): monitora as políticas de rede do Kubernetes na API do Kubernetes e sincroniza as políticas com o armazenamento de dados (<code>etcd</code>) como políticas de rede do Calico. O Felix (componente que opera em cada um dos <em>nodes</em> do <em>cluster</em>, parte do DaemonSet <code>calico-node</code>) implementa políticas de rede no plano de dados. Documentação de referência do Felix: <a href="https://docs.tigera.io/calico/latest/reference/felix/configuration" class="bare">https://docs.tigera.io/calico/latest/reference/felix/configuration</a> .</p>
</li>
<li>
<p>Controlador de namespaces (<em>namespace controller</em>): monitora <em>namespaces</em> e configura perfis do Calico.</p>
</li>
<li>
<p>Controlador de contas de serviço (<em>serviceaccount controller</em>): monitora contas de serviço e configura perfis do Calico.</p>
</li>
<li>
<p>Controlador de <em>workload endpoints</em> (<em>workloadendpoint controller</em>): monitora as mudanças nos <em>labels</em> dos pods e atualiza os <em>workload endpoints</em> do Calico.</p>
</li>
<li>
<p>Controlador de <em>nodes</em> (<em>node controller</em>): monitora a remoção de <em>nodes</em> do Kubernetes e remove os dados correspondentes do Calico, e opcionalmente monitora atualizações de node para criar e sincronizar <em>host endpoints</em> cada <em>node</em>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Todos esses controladores operam em um único pod no Deployment <code>calico-kube-controllers</code>.</p>
</div>
</div>
</details>
</li>
<li>
<p>Semelhantemente à questão anterior, qual a função dos pods no DaemonSet <code>calico-node</code>? Quais seus componentes?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>O <code>calico-node</code> é responsável por gerenciar e garantir a conectividade de rede, roteamento e políticas de segurança no <em>cluster</em> Kubernetes. O pod <code>calico-node</code> é implantado em todos os <em>nodes</em> do <em>cluster</em> (por meio de um DaemonSet) e executa três <em>daemons</em> internos:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Felix: <em>daemon</em> do Calico que é executado em todos os nodes e fornece <em>endpoints</em>.</p>
</li>
<li>
<p>BIRD: <em>daemon</em> BGP que distribui informações de roteamento para outros nodes.</p>
</li>
<li>
<p>confd: um <em>daemon</em> que monitora o armazenamento de dados do Calico em busca de alterações de configuração e atualiza os arquivos de configuração do BIRD.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Para instalações baseadas em manifesto (isto é, arquivos YAML), o <code>calico-node</code> é configurado principalmente por meio de variáveis de ambiente. Os <em>nodes</em> individuais também podem ser atualizados por meio do recurso personalizado (CRD&#8201;&#8212;&#8201;<em>custom resource definition</em>) <code>Node</code>. Além disso, o <code>calico-node</code> pode também ser configurado por meio do <em>Calico Operator</em>.</p>
</div>
</div>
</details>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_3_2_configuração_ipam">3.2) Configuração IPAM</h4>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Quais são os recursos customizados (CRDs) definidos pelo Calico?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Podemos utilizar o comando <code>kubectl api-resources</code> para obter essa informação:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl api-resources | grep 'calico'</strong>
bgpconfigurations                              crd.projectcalico.org/v1               false        BGPConfiguration
bgppeers                                       crd.projectcalico.org/v1               false        BGPPeer
blockaffinities                                crd.projectcalico.org/v1               false        BlockAffinity
caliconodestatuses                             crd.projectcalico.org/v1               false        CalicoNodeStatus
clusterinformations                            crd.projectcalico.org/v1               false        ClusterInformation
felixconfigurations                            crd.projectcalico.org/v1               false        FelixConfiguration
globalnetworkpolicies                          crd.projectcalico.org/v1               false        GlobalNetworkPolicy
globalnetworksets                              crd.projectcalico.org/v1               false        GlobalNetworkSet
hostendpoints                                  crd.projectcalico.org/v1               false        HostEndpoint
ipamblocks                                     crd.projectcalico.org/v1               false        IPAMBlock
ipamconfigs                                    crd.projectcalico.org/v1               false        IPAMConfig
ipamhandles                                    crd.projectcalico.org/v1               false        IPAMHandle
ippools                                        crd.projectcalico.org/v1               false        IPPool
ipreservations                                 crd.projectcalico.org/v1               false        IPReservation
kubecontrollersconfigurations                  crd.projectcalico.org/v1               false        KubeControllersConfiguration
networkpolicies                                crd.projectcalico.org/v1               true         NetworkPolicy
networksets                                    crd.projectcalico.org/v1               true         NetworkSet</pre>
</div>
</div>
<div class="paragraph">
<p>Note que apenas os dois últimos recursos, <code>networkpolicies</code> e <code>networksets</code> são específicos para <em>namespaces</em>, e não <em>cluster-wide</em>.</p>
</div>
</div>
</details>
</li>
<li>
<p>Qual desses recursos contém a faixa de endereços de rede (<em>IP Pool</em>) alocável pelo Calico a pods criados no <em>cluster</em>? De posse dessa informação, responda:</p>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>Qual é a faixa de endereços utilizáveis nessa rede?</p>
</li>
<li>
<p>Qual é o o endereço de <em>broadcast</em> da rede?</p>
</li>
<li>
<p>Qual é o número de possíveis <em>hosts</em> (excluindo-se o endereço da rede e o de <em>broadcast</em>)?</p>
</li>
<li>
<p>Qual é a máscara de rede, em formato longo (p.ex. <code>255.255.255.255</code>)? E em formato CIDR?</p>
</li>
</ul>
</div>
</div>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Para descobrir essa informação podemos consultar quais IP Pools existem no <em>cluster</em>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get IPPool</strong>
NAME                  AGE
default-ipv4-ippool   16h</pre>
</div>
</div>
<div class="paragraph">
<p>O que esse IP Pool define?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get IPPool default-ipv4-ippool -o yaml | yq .spec</strong>
allowedUses:
  - Workload
  - Tunnel
blockSize: 26
cidr: 10.32.0.0/12
ipipMode: Always
natOutgoing: true
nodeSelector: all()
vxlanMode: Never</pre>
</div>
</div>
<div class="paragraph">
<p>Como visto, a faixa utilizável padrão de IPs definida para o Calico é <code>10.32.0.0/12</code>. Usando uma calculadora de sub-redes IP, como <a href="https://www.calculator.net/ip-subnet-calculator.html" class="bare">https://www.calculator.net/ip-subnet-calculator.html</a> , é simples determinar as informações solicitadas:</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>Faixa de endereços utilizáveis: de <code>10.32.0.1</code> a <code>10.47.255.254</code>.</p>
</li>
<li>
<p>Endereço de <em>broadcast</em>: <code>10.47.255.255</code></p>
</li>
<li>
<p>Número de possíveis <em>hosts</em>: <code>1.048.574</code> (um milhão, quarenta e oito mil, quinhentos e setenta e quatro <em>hosts</em>)</p>
</li>
<li>
<p>Máscara de rede em formato longo: <code>255.240.0.0</code></p>
</li>
<li>
<p>Máscara de rede em formato CIDR: <code>/12</code></p>
</li>
</ul>
</div>
</div>
</div>
</div>
</details>
</li>
<li>
<p>As informações do item anterior são fundamentais para o funcionamento do serviço IPAM (<em>IP Address Management</em>) do Calico. Esse serviço associa blocos da faixa utilizável para que <em>nodes</em> possam associar endereços IP aos pods operando dentro deles. Quais são as faixas associadas a cada um dos <em>nodes</em> do <em>cluster</em>, no momento?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Essa informação fica armazenada no CRD <code>BlockAffinity</code>, como visto abaixo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get BlockAffinity</strong>
NAME                           AGE
s2-master-1-10-45-193-192-26   16h
s2-node-1-10-41-181-128-26     16h</pre>
</div>
</div>
<div class="paragraph">
<p>Consultando cada um desses elementos podemos determinar as faixas presentemente associadas a cada um dos <em>nodes</em> do <em>cluster</em>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get BlockAffinity s2-master-1-10-45-193-192-26 -o yaml | yq .spec</strong>
cidr: 10.45.193.192/26
deleted: "false"
node: s2-master-1
state: confirmed</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get BlockAffinity s2-node-1-10-41-181-128-26 -o yaml | yq .spec</strong>
cidr: 10.41.181.128/26
deleted: "false"
node: s2-node-1
state: confirmed</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Como o Calico sabe quais endereços IP estão em uso em um dado bloco?</p>
<div class="paragraph">
<p>Demonstre sua explicação criando um novo pod com qualquer nome/imagem e observando o endereço IP associado a ele. Aponte precisamente como o endereço associado foi consumido da faixa disponível no bloco, evitando conflitos de endereço com pods a serem futuramente criados.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Essa informação fica armazenada no CRD <code>IPAMBlock</code>, como visto abaixo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get IPAMBlock</strong>
NAME               AGE
10-41-181-128-26   16h
10-45-193-192-26   16h</pre>
</div>
</div>
<div class="paragraph">
<p>A faixa de endereços livres (i.e. não-alocados) pode ser vista no atributo <code>.spec.unallocated</code> desse recurso, como visto abaixo para o <em>node</em> <code>s2-node-1</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get IPAMBlock 10-41-181-128-26 -o yaml | yq .spec.unallocated | awk '{print $NF}' | sort -n</strong>
1
2
3
6
7
8
9
10

(...)</pre>
</div>
</div>
<div class="paragraph">
<p>Primeiro, vamos salvar a saída acima para um arquivo. Em seguida, iremos criar um novo pod com um nome/imagem qualquer e verificar seu endereço IP. Finalmente, vamos comparar o conteúdo do <code>IPAMBlock</code> após a criação do pod com seu conteúdo anterior:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get IPAMBlock 10-41-181-128-26 -o yaml | yq .spec.unallocated | awk '{print $NF}' | sort -n > ipamblock_pre_pod_creation.out</strong></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl run web --image=nginx:alpine</strong></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get IPAMBlock 10-41-181-128-26 -o yaml | yq .spec.unallocated | awk '{print $NF}' | sort -n > ipamblock_post_pod_creation.out</strong></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># diff -u ipamblock_pre_pod_creation.out ipamblock_post_pod_creation.out</strong>
--- ipamblock_pre_pod_creation.out      2023-05-06 13:46:23.484158637 0000
++ ipamblock_post_pod_creation.out     2023-05-06 13:46:45.351086447 +0000
@@ -8,7 +8,6 @@
 10
 11
 12
-13
 14
 15
 16</pre>
</div>
</div>
<div class="paragraph">
<p>Note, no exemplo acima, que o número (ou, nesse caso, endereço) <code>13</code> não figura no atributo <code>.spec.unallocated</code> do <code>IPAMBlock</code> após a criação do pod. Note ainda que a faixa original do bloco associado ao <em>node</em> <code>s2-node-1</code> é <code>10.41.181.128/26</code>. Faça a soma: <code>128 + 13 = 141</code>. Qual endereço IP foi associado ao pod, afinal?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pod web -o wide</strong>
NAME   READY   STATUS    RESTARTS   AGE     IP              NODE        NOMINATED NODE   READINESS GATES
web    1/1     Running   0          2m35s   10.41.181.141   s2-node-1   &lt;none&gt;           &lt;none&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>Fica claro, portanto, como o Calico consegue determinar a alocação de endereços IP através de seus CRDs.</p>
</div>
</div>
</details>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Os IP Pools do Calico são extremamente poderosos, e permitem também a associação de faixas de endereços por pod e por <em>node</em>, como documentado em <a href="https://docs.tigera.io/calico/latest/reference/configure-cni-plugins#ipam-1" class="bare">https://docs.tigera.io/calico/latest/reference/configure-cni-plugins#ipam-1</a> .</p>
</div>
<div class="paragraph">
<p>Adicionalmente, desde a versão 3.3 do Calico é também possível associar faixas de endereços por <em>namespace</em>, como demonstrado em <a href="https://www.tigera.io/blog/calico-ipam-explained-and-enhanced/" class="bare">https://www.tigera.io/blog/calico-ipam-explained-and-enhanced/</a> . Isso é especialmente útil para assinalar faixas para usuários, aplicações ou equipes específicas, permitindo que firewalls externos sejam configurados com regras estáticas baseadas nessas faixas.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_3_3_políticas_de_rede">3.3) Políticas de rede</h4>
<div class="paragraph">
<p>Vimos como implementar políticas de rede no Kubernetes durante a sessão 6 utilizando <code>NetworkPolicies</code> nativas do Kubernetes. Embora funcionais, o Calico nos oferece a possibilidade de usar CRDs do tipo <code>NetworkPolicy</code> (sim, os nomes são iguais) com funcionalidades adicionais que podem ser úteis em casos específicos.</p>
</div>
<div class="paragraph">
<p>As <code>NetworkPolicies</code> nativas do Kubernetes são limitadas a regras baseadas em endereços IP e <em>labels</em> de pod, enquanto as <code>NetworkPolicies</code> do Calico oferecem maior flexibilidade e granularidade no controle de tráfego de rede. Algumas das funcionalidades adicionais fornecidas pelas <code>NetworkPolicies</code> do Calico incluem:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Suporte a seletores de <em>namespace</em>: isso permite aplicar políticas de rede específicas a <em>namespaces</em> inteiros, facilitando a segmentação de redes em ambientes <em>multi-tenant</em>.</p>
</li>
<li>
<p>Políticas globais e hierárquicas: As <code>NetworkPolicies</code> do Calico oferecem suporte a políticas globais que se aplicam a todos os pods no cluster, bem como políticas hierárquicas que podem ser herdadas e sobrepostas, permitindo um controle de acesso mais refinado.</p>
</li>
<li>
<p>Controle de tráfego baseado em serviços: O Calico permite aplicar políticas de rede a grupos de pods que são selecionados com base em seus serviços associados, permitindo um controle mais preciso sobre o tráfego de rede entre os componentes da aplicação.</p>
</li>
<li>
<p>Filtragem de tráfego baseada em protocolos de aplicação: As NetworkPolicies do Calico podem aplicar regras baseadas em protocolos de aplicação, como HTTP e DNS.</p>
</li>
<li>
<p>Proteção de <em>endpoint</em> de host: O Calico pode proteger os <em>endpoints</em> de host (isto é, os <em>nodes</em> do <em>cluster</em> Kubernetes), aplicando políticas de rede em nível de host, além dos pods.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Essas funcionalidades adicionais podem ser especialmente úteis em ambientes de grande escala e complexidade, onde há uma necessidade maior de controle refinado sobre o tráfego de rede e a segmentação de segurança. Iremos explorar um desses casos nesta atividade.</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Crie o namespace <code>npc</code> e, dentro dele, dois pods:</p>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p><code>web</code>, utilizando a imagem <code>fbscarel/myapp-mysql</code>. Definas as variáveis de ambiente <code>DBHOST=db</code> e <code>DBPASS=secret</code>  Exponha o pod utilizando um serviço do tipo NodePort, utilizando a porta 80 do container e mapeando-a para a porta 31080 do <em>host</em>.</p>
</li>
<li>
<p><code>db</code>, utilizando a imagem <code>mysql:5.6</code>. Defina a senha do usuário <code>root</code> com o mesmo valor da variável <code>DBPASS</code>, usada no pod <code>app</code>. Finalmente, exponha a porta 3306 do pod dentro do contexto do <em>cluster</em>.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Teste o funcionamento da aplicação, antes de prosseguir.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Primeiro, crie o namespace.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl create namespace npc</strong>
namespace/npc created</pre>
</div>
</div>
<div class="paragraph">
<p>A seguir, crie o pod <code>web</code> com as opções especificadas. Não se esqueça de seu serviço, do tipo <code>NodePort</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n npc run web --image=fbscarel/myapp-mysql -l app=web --env="DBHOST=db" --env="DBPASS=secret"</strong>
pod/web created</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n npc create svc nodeport web --tcp=80 --node-port=31080</strong>
service/web created</pre>
</div>
</div>
<div class="paragraph">
<p>Agora, para o pod <code>db</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n npc run db --image=mysql:5.6 -l app=db --env="MYSQL_ROOT_PASSWORD=secret" --port=3306 --expose</strong>
service/db created
pod/db created</pre>
</div>
</div>
<div class="paragraph">
<p>Para facilitar a visualização da aplicação em ambiente console, utilizaremos o navegador <code>w3m</code>. Se preferir, pode utilizar os comandos <code>wget</code> ou <code>curl</code>, que imprimem o HTML não-processado na tela.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># apt install -y w3m</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Podemos executar o <code>w3m</code> de forma não-interativa usando a opção <code>-dump</code>. Na saída, buscamos o <em>status</em> da conexão com o banco de dados.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># w3m -dump http://localhost:31080 | grep status</strong>
Connection status: SUCCESS</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Crie uma <code>NetworkPolicy</code> sob a API <code>projectcalico.org/v3</code> que bloqueie todo o tráfego com destino ao pod <code>db</code> e realize o <em>logging</em> do tráfego bloqueado. Consulte a documentação em <a href="https://docs.tigera.io/calico/latest/network-policy/get-started/calico-policy/calico-network-policy#generate-logs-for-specific-traffic" class="bare">https://docs.tigera.io/calico/latest/network-policy/get-started/calico-policy/calico-network-policy#generate-logs-for-specific-traffic</a> para descobrir como fazer isso.</p>
<div class="paragraph">
<p>Note que para realizar o passo acima será necessário usar o comando <code>calicoctl</code>, e não o <code>kubectl</code> como usual.</p>
</div>
<div class="paragraph">
<p>A seguir, tente conectar-se à aplicação novamente: o que ocorre?</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Para aplicar <code>NetworkPolicies</code> específicas do Calico devemos usar o comando <code>calicoctl</code> em lugar do <code>kubectl</code>, como mencionado pelo enunciado. Vamos instalá-lo no <em>host</em> local seguindo os passos em <a href="https://docs.tigera.io/calico/latest/operations/calicoctl/install#install-calicoctl-as-a-binary-on-a-single-host" class="bare">https://docs.tigera.io/calico/latest/operations/calicoctl/install#install-calicoctl-as-a-binary-on-a-single-host</a> .</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl -L https://github.com/projectcalico/calico/releases/latest/download/calicoctl-linux-amd64 -o calicoctl &&
chmod +x calicoctl &&
mv calicoctl /usr/local/bin</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Teste a correta instalação do <code>calicoctl</code> usando o parâmetro <code>version</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># calicoctl version</strong>
Client Version:    v3.25.1
Git commit:        82dadbce1
Cluster Version:   v3.25.1
Cluster Type:      k8s,bgp,kubeadm,kdd</pre>
</div>
</div>
<div class="paragraph">
<p>Com o <code>calicoctl</code> podemos prosseguir com a criação da política de rede, que é bem simples. Utilize o arquivo YAML abaixo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">projectcalico.org/v3</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">NetworkPolicy</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">npc-db-netpol</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">npc</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">selector</span><span class="pi">:</span> <span class="s">app == 'db'</span>
  <span class="na">ingress</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">action</span><span class="pi">:</span> <span class="s">Log</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>A seguir, crie o objeto usando o <code>calicoctl</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># calicoctl apply -f npc-db-netpol.yaml</strong>
Successfully applied 1 'NetworkPolicy' resource(s)</pre>
</div>
</div>
<div class="paragraph">
<p>Depois, tente conectar-se novamente à aplicação. Pode demorar algum tempo para atingir o tempo-limite do comando abaixo&#8201;&#8212;&#8201;seja paciente.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># w3m -dump http://localhost:31080 | grep status</strong>
Connection status: FAILURE</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Mas, onde estão os logs? Determine em qual dos <em>hosts</em> do <em>cluster</em> os pods do <em>namespace</em> <code>npc</code> estão executando, acesse-o via SSH e veja o conteúdo do arquivo <code>/var/log/messages</code>. Há algo de interessante ali?</p>
<div class="paragraph">
<p>Qual seria a utilidade desse recurso em um ambiente de produção?</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Antes de consultar o arquivo de log em questão, é primeiro necessário descobrir em qual <em>node</em> os pods estão executando:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n npc get pod -o custom-columns=NAME:.metadata.name,NODE:.spec.nodeName</strong>
NAME   NODE
db     s2-node-1
web    s2-node-1</pre>
</div>
</div>
<div class="paragraph">
<p>Certo, vamos acessar o <em>node</em> <code>s2-node-1</code> via SSH como <code>root</code>, então.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># whoami ; hostname</strong>
root
s2-node-1</pre>
</div>
</div>
<div class="paragraph">
<p>A seguir, vamos visualizar o conteúdo recente do arquivo <code>/var/log/messages</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># tail -n3 /var/log/messages</strong>
May  6 14:28:24 s2-node-1 kernel: [ 7365.174876] calico-packet: IN=cali945ac7714c6 OUT=calie2d9c08122c MAC=ee:ee:ee:ee:ee:ee:82:6c:21:5e:2c:c9:08:00 SRC=10.41.181.142 DST=10.41.181.143 LEN=60 TOS=0x00 PREC=0x00 TTL=63 ID=19390 DF PROTO=TCP SPT=42620 DPT=3306 WINDOW=64800 RES=0x00 SYN URGP=0
May  6 14:28:41 s2-node-1 kernel: [ 7381.302845] calico-packet: IN=cali945ac7714c6 OUT=calie2d9c08122c MAC=ee:ee:ee:ee:ee:ee:82:6c:21:5e:2c:c9:08:00 SRC=10.41.181.142 DST=10.41.181.143 LEN=60 TOS=0x00 PREC=0x00 TTL=63 ID=19391 DF PROTO=TCP SPT=42620 DPT=3306 WINDOW=64800 RES=0x00 SYN URGP=0
May  6 14:29:14 s2-node-1 kernel: [ 7414.891072] calico-packet: IN=cali945ac7714c6 OUT=calie2d9c08122c MAC=ee:ee:ee:ee:ee:ee:82:6c:21:5e:2c:c9:08:00 SRC=10.41.181.142 DST=10.41.181.143 LEN=60 TOS=0x00 PREC=0x00 TTL=63 ID=19392 DF PROTO=TCP SPT=42620 DPT=3306 WINDOW=64800 RES=0x00 SYN URGP=0</pre>
</div>
</div>
<div class="paragraph">
<p>Excelente! Os pacotes com direção ao pod <code>web</code> no <em>namespace</em> <code>npc</code> foram logados antes de seu bloqueio, como objetivado pela <code>NetworkPolicy</code>. Note que o formato de log é exatamente o mesmo adotado pelo <code>iptables</code>&#8201;&#8212;&#8201;de fato, é o próprio <code>iptables</code> que realiza o <em>logging</em> de tráfego, como evidenciado pelo comando abaixo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># iptables -L -vn | grep npc-db-netpol</strong>
    0     0 LOG        all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* cali:FLjsE4KN0RR8L81t */ /* Policy npc/default.npc-db-netpol ingress */ LOG flags 0 level 5 prefix "calico-packet: "</pre>
</div>
</div>
<div class="paragraph">
<p>Como documentado em <a href="https://docs.tigera.io/calico/latest/reference/architecture/data-path" class="bare">https://docs.tigera.io/calico/latest/reference/architecture/data-path</a> , o Calico utiliza o roteamento e <em>firewalling</em> nativos do Linux para implementar as políticas de tráfego selecionadas pelo usuário.</p>
</div>
</div>
</details>
</li>
<li>
<p>Antes de prosseguir, remova o namespace <code>npc</code>:</p>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete ns npc</strong>
namespace "npc" deleted</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_4_redes_de_serviços">4) Redes de serviços</h3>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Qual é a faixa de endereços IP configurada para os serviços criados no <em>cluster</em>? E quanto à faixa de portas para serviços do tipo <code>NodePort</code>?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Como documentado em <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/" class="bare">https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/</a> , a faixa de endereços configurada para os serviços criados no <em>cluster</em> é definida pela opção <code>--service-cluster-ip-range</code>. Esta variável é definida no arquivo <em>manifest</em> do <code>kube-apiserver</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># grep service-cluster-ip-range /etc/kubernetes/manifests/kube-apiserver.yaml</strong>
    - --service-cluster-ip-range=10.96.0.0/12</pre>
</div>
</div>
<div class="paragraph">
<p>Pode-se obter o mesmo valor verificando a configuração corrente do <em>cluster</em> com o comando <code>kubectl cluster-info</code>. Veja:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl cluster-info dump | grep -m 1 service-cluster-ip-range</strong>
                            "--service-cluster-ip-range=10.96.0.0/12",</pre>
</div>
</div>
<div class="paragraph">
<p>A faixa de portas dedicada a serviços do tipo <code>NodePort</code> é documentada na mesma URL, e ajustada via opção <code>service-node-port-range</code>. Vejamos seu valor corrente:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl cluster-info dump | grep service-node-port-range</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Como a variável encontra-se indefinida, o valor padrão é utilizado: a faixa de portas variando entre 30000 e 32767, inclusivo.</p>
</div>
</div>
</details>
</li>
<li>
<p>Quantos pods do <code>kube-proxy</code> estão em operação? De que forma o ambiente garante que eles executarão em cada um dos <em>nodes</em> do <em>cluster</em>?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vejamos:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system get pod -l k8s-app=kube-proxy</strong>
NAME               READY   STATUS    RESTARTS   AGE
kube-proxy-69v4h   1/1     Running   0          3d2h
kube-proxy-qqf5c   1/1     Running   0          3d2h</pre>
</div>
</div>
<div class="paragraph">
<p>Determine em quais <em>nodes</em> os pods do <code>kube-proxy</code> estão executando.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system get pod -l k8s-app=kube-proxy -o custom-columns=NAME:.metadata.name,NODE:.spec.nodeName</strong>
NAME               NODE
kube-proxy-69v4h   s2-node-1
kube-proxy-qqf5c   s2-master-1</pre>
</div>
</div>
<div class="paragraph">
<p>O motivo para a saída acima é simples: como seria de se imaginar, o <code>kube-proxy</code> é implementado como um DaemonSet.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system get ds kube-proxy</strong>
NAME         DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
kube-proxy   2         2         2       2            2           kubernetes.io/os=linux   3d2h</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Qual tipo de proxy (<code>ProxyMode</code>) está sendo utilizado pelo <code>kube-proxy</code>?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Para determinar a informação acima precisamos saber como é feita a configuração do <code>kube-proxy</code>. Verifique o DaemonSet, e veja o valor da opção <code>--config</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system describe ds kube-proxy | grep /var/lib/kube-proxy</strong>
      --config=/var/lib/kube-proxy/config.conf
      /var/lib/kube-proxy from kube-proxy (rw)</pre>
</div>
</div>
<div class="paragraph">
<p>Podemos inferir então que o processo lê o arquivo <code>config.conf</code> dentro do diretório <code>/var/lib/kube-proxy</code>, e que este é montado a partir de um recurso com o nome <code>kube-proxy</code>. Veja a seção <code>Volumes</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system describe ds kube-proxy | grep Volumes -A4</strong>
  Volumes:
   kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false</pre>
</div>
</div>
<div class="paragraph">
<p>Trata-se, portanto, de um ConfigMap. Buscando a opção <code>mode</code> nesse recurso, constatamos que ela se encontra vazia.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system describe cm kube-proxy | grep mode</strong>
mode: ""</pre>
</div>
</div>
<div class="paragraph">
<p>Como documentado em <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/" class="bare">https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/</a> a opção <code>--proxy-mode</code> define o tipo de <em>proxy</em> a ser usado pelo <code>kube-proxy</code>. Se vazia, a melhor opção é automaticamente selecionada&#8201;&#8212;&#8201;no caso de ambientes Linux, <code>iptables</code>.</p>
</div>
<div class="paragraph">
<p>Outro curiosidade: no <code>kube-proxy</code>, a opção <code>--cluster-cidr</code> é utilizada para definir a faixa de endereços padrão do <em>cluster</em> Kubernetes, definida no ConfigMap por um atribuito homônimo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system describe cm kube-proxy | grep clusterCIDR</strong>
clusterCIDR: 10.32.0.0/12</pre>
</div>
</div>
<div class="paragraph">
<p>Esse mesmo valor é definido no arquivo <em>manifest</em> do <code>kube-controller-manager</code>, como visto abaixo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># grep cluster-cidr /etc/kubernetes/manifests/kube-controller-manager.yaml</strong>
    - --cluster-cidr=10.32.0.0/12</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Vamos verificar o impacto desse <code>ProxyMode</code> no ambiente. Crie o pod <code>proxy</code> utilizando a imagem <code>nginx:alpine</code>. A seguir, exponha-o dentro do contexto do <em>cluster</em>, criando um serviço com o nome <code>proxy-cluster</code> que mapeie a porta 8880 do serviço para a porta 80 do pod.</p>
<div class="paragraph">
<p>Teste o funcionamento de sua configuração.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Primeiro, crie o pod solicitado.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl run proxy --image=nginx:alpine</strong>
pod/proxy created</pre>
</div>
</div>
<div class="paragraph">
<p>Como o serviço do tipo <code>ClusterIP</code> deve especificar parâmetros <code>port</code> e <code>targetPort</code> diferentes, iremos criá-lo via arquivo YAML:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">proxy-cluster</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ports</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">proxy-cluster</span>
    <span class="na">port</span><span class="pi">:</span> <span class="m">8880</span>
    <span class="na">targetPort</span><span class="pi">:</span> <span class="m">80</span>
    <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">run</span><span class="pi">:</span> <span class="s">proxy</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">ClusterIP</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f proxy-cluster.yaml</strong>
service/proxy-cluster created</pre>
</div>
</div>
<div class="paragraph">
<p>Para testar o funcionamento do ambiente, lance um pod qualquer com o binário <code>curl</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl run curl --image=curlimages/curl -- sleep 3600</strong>
pod/curl created</pre>
</div>
</div>
<div class="paragraph">
<p>Depois, use o <code>curl</code> para validar o acesso ao recurso.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl exec -it curl -- curl -s http://proxy-cluster:8880 | grep title</strong>
&lt;title&gt;Welcome to nginx!&lt;/title&gt;</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Agora, para uma atividade um pouco complexa: investigue a configuração do firewall do <em>host</em> (utilizando o comando <code>iptables</code>), e responda: como é realizada a configuração do firewall, e como esta garante que o tráfego com destino ao serviço <code>proxy-cluster</code>&#8201;&#8212;&#8201;e, em última instância, ao pod <code>proxy</code>&#8201;&#8212;&#8201;é corretamente direcionado.</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Para facilitar a leitura dos comandos que se seguem, veja primeiramente o cabeçalho de saída do comando <code>iptables</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># iptables -L -vn -t nat | sed -n 2p</strong>
 pkts bytes target     prot opt in     out     source               destination</pre>
</div>
</div>
<div class="paragraph">
<p>Em ordem, serão exibidos:</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>Número de pacotes processados pela regra.</p>
</li>
<li>
<p>Número total de bytes que casaram com a regra.</p>
</li>
<li>
<p><em>Chain</em>-alvo da regra em questão.</p>
</li>
<li>
<p>Protocolo aplicável (p.ex. TCP ou UDP).</p>
</li>
<li>
<p>Diferentes opções habilitadas no cabeçalho IP (p.ex. SACK ou <em>record route</em>).</p>
</li>
<li>
<p>Interface de entrada.</p>
</li>
<li>
<p>Interface de saída.</p>
</li>
<li>
<p>Endereço ou rede de origem.</p>
</li>
<li>
<p>Endereço ou rede de destino.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Primeiro, vejamos quais regras batem com a porta escolhida para o serviço: <code>8880</code>. Note que removeremos regras com a <em>string</em> <code>MARK</code>, usada internamente para marcação de pacotes (e que não afetam o sentido do tráfego a ser analisado).</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># iptables -L -vn -t nat | grep ':8880$' | grep -v 'MARK'</strong>
    0     0 KUBE-SVC-Y74VRPK3SXSEYTOE  tcp  --  *      *       0.0.0.0/0            10.104.100.26        /* default/proxy-cluster:proxy-cluster cluster IP */ tcp dpt:8880</pre>
</div>
</div>
<div class="paragraph">
<p>Temos, portanto, que quaisquer pacotes com endereço de destino igual a <code>10.96.164.88</code> e porta de destino igual a <code>8880</code> serão redirecionados para a <em>chain</em> <code>KUBE-SVC-Y74VRPK3SXSEYTOE</code>. Mas, porque esse IP e porta específicos?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get svc proxy-cluster -o wide</strong>
NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE   SELECTOR
proxy-cluster   ClusterIP   10.104.100.26   &lt;none&gt;        8880/TCP   92s   run=proxy</pre>
</div>
</div>
<div class="paragraph">
<p>Ah, sim! O serviço <code>proxy-cluster</code> possui esse IP e porta-alvos.</p>
</div>
<div class="paragraph">
<p>Bom, para a próxima pergunta: qual o conteúdo da <em>chain</em> <code>KUBE-SVC-Y74VRPK3SXSEYTOE</code>?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># iptables -vn -t nat -L KUBE-SVC-Y74VRPK3SXSEYTOE | grep -v 'MARK'</strong>
Chain KUBE-SVC-Y74VRPK3SXSEYTOE (1 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 KUBE-SEP-Z3PIB5TFYNKZTO6S  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/proxy-cluster:proxy-cluster -&gt; 10.41.181.147:80 */</pre>
</div>
</div>
<div class="paragraph">
<p>Nada de mais: todo o tráfego direcionado para essa <em>chain</em> é redirecionado para a <em>chain</em> <code>KUBE-SEP-Z3PIB5TFYNKZTO6S</code>. Vamos visualizá-la:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># iptables -vn -t nat -L KUBE-SEP-Z3PIB5TFYNKZTO6S | grep -v 'MARK'</strong>
Chain KUBE-SEP-Z3PIB5TFYNKZTO6S (1 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/proxy-cluster:proxy-cluster */ tcp to:10.41.181.147:80</pre>
</div>
</div>
<div class="paragraph">
<p>Temos uma regra de DNAT (<em>Destination NAT</em>) em que todos os pacotes aplicáveis são alterados: o endereço de destino é reescrito para <code>10.41.181.147</code>, e a porta de destino para <code>80</code>. Porque utilizar esse IP e porta específicos?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pod proxy -o custom-columns=NAME:.metadata.name,IPADDR:.status.podIP</strong>
NAME    IPADDR
proxy   10.41.181.147</pre>
</div>
</div>
<div class="paragraph">
<p>Trata-se da combinação de IP/porta do pod que contém a aplicação a ser exposta, <code>proxy</code>. Fica, portanto, bastante claro o caminho que os pacotes fazem dentro do firewall de <strong>todos</strong> os <em>nodes</em> do <em>cluster</em>.</p>
</div>
<div class="paragraph">
<p>Agora, para outra pergunta: como os <em>nodes</em> sabem como atingir o pod <code>proxy</code>, com endereço <code>10.41.181.147</code>? Consulte sua tabela de rotas:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ip r s | grep '10.41.181'</strong>
10.41.181.128/26 via 192.168.68.25 dev tunl0 proto bird onlink</pre>
</div>
</div>
<div class="paragraph">
<p>Ora, para atingir a rede <code>10.41.181.128/26</code> os pacotes são roteados para o endereço <code>192.168.68.25</code>. Em que <em>node</em> o pod <code>proxy</code> está executando mesmo?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pod proxy -o wide</strong>
NAME    READY   STATUS    RESTARTS   AGE     IP              NODE        NOMINATED NODE   READINESS GATES
proxy   1/1     Running   0          6m38s   10.41.181.147   s2-node-1   &lt;none&gt;           &lt;none&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>Sem surpresas, o pod <code>proxy</code> está executando precisamente na máquina que tem o endereço <code>192.168.68.25</code> associado, <code>s2-node-1</code>.</p>
</div>
<div class="paragraph">
<p>Os comandos acima foram executados na máquina <code>s2-master-1</code>. E como fica a configuração de rota no <em>host</em> <code>s2-node-1</code>? Veja abaixo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># hostname ; whoami</strong>
s2-node-1
root</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ip route show | grep '10.41.181'</strong>
blackhole 10.41.181.128/26 proto bird
10.41.181.144 dev cali3e26a231eb1 scope link
10.41.181.145 dev cali74fbd1638c9 scope link
10.41.181.147 dev cali7167a7dc8bc scope link
10.41.181.148 dev cali35e3a5cb80b scope link</pre>
</div>
</div>
<div class="paragraph">
<p>O endereço do pod <code>proxy</code>, <code>10.41.181.147</code> é mostrado como estando diretamente conectado à interface <code>cali7167a7dc8bc</code>. Que interface é essa?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ip addr show cali7167a7dc8bc</strong>
11: cali7167a7dc8bc@if4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1480 qdisc noqueue state UP group default
    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 2
    inet6 fe80::ecee:eeff:feee:eeee/64 scope link
       valid_lft forever preferred_lft forever</pre>
</div>
</div>
<div class="paragraph">
<p>Trata-se de uma interface virtual da interface <code>if4</code>. E qual seria essa?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ip addr show if4</strong>
4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:9e:f9:3f:3c brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever</pre>
</div>
</div>
<div class="paragraph">
<p>Essa é a interface <code>bridge</code> utilizada pelo <em>daemon</em> Docker para prover acesso à rede aos containers em execução. Finalmente, o ciclo está fechado.</p>
</div>
<div class="paragraph">
<p>Antes de continuar, retorne à máquina <code>s2-master-1</code> como <code>root</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># hostname ; whoami</strong>
s2-master-1
root</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Compreendido o caminho de comunicação de um serviço do tipo <code>ClusterIP</code>, vamos agora investigar um serviço do tipo <code>NodePort</code>.</p>
<div class="paragraph">
<p>Primeiro, remova o serviço <code>proxy-cluster</code>. A seguir, crie um serviço com o nome <code>proxy-node</code> que mapeie a porta 30880 do <em>node</em> para a 8880 do serviço; esta, por sua vez, deve mapear para a porta 80 do pod.</p>
</div>
<div class="paragraph">
<p>Teste o funcionamento de sua configuração.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Começamos removendo o serviço <code>proxy-cluster</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete svc proxy-cluster</strong>
service "proxy-cluster" deleted</pre>
</div>
</div>
<div class="paragraph">
<p>Depois, criamos o serviço <code>proxy-node</code> usando o arquivo YAML abaixo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">proxy-node</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ports</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">proxy-node</span>
    <span class="na">nodePort</span><span class="pi">:</span> <span class="m">30880</span>
    <span class="na">port</span><span class="pi">:</span> <span class="m">8880</span>
    <span class="na">targetPort</span><span class="pi">:</span> <span class="m">80</span>
    <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">run</span><span class="pi">:</span> <span class="s">proxy</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">NodePort</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f proxy-node.yaml</strong>
service/proxy-node created</pre>
</div>
</div>
<div class="paragraph">
<p>Para testar a acessibilidade do serviço, basta utilizar o binário <code>curl</code> de um ponto externo ao <em>cluster</em>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl -s http://localhost:30880 | grep title</strong>
&lt;title&gt;Welcome to nginx!&lt;/title&gt;</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Investigue a configuração do firewall do <em>host</em> e determine de que forma o tráfego com destino ao serviço <code>proxy-node</code> é direcionado ao pod <code>proxy</code>. Explique o que ocorre nos seguintes cenários:</p>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>Um cliente externo quer comunicar-se com o pod <code>proxy</code>.</p>
</li>
<li>
<p>Um pod dentro do <em>cluster</em> quer comunicar-se com o pod <code>proxy</code>.</p>
</li>
</ul>
</div>
</div>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>A análise de tráfego do firewall não é muito diferente do caso anterior, num serviço do tipo <code>ClusterIP</code>. Veja que para o tráfego interno ao <em>cluster</em>, com destino ao IP <code>10.111.101.95</code> e porta <code>8880</code>, este é redirecionado à <em>chain</em> <code>KUBE-SVC-3H37ZQYOAV4SUDJJ</code>.</p>
</div>
<div class="paragraph">
<p>Para pacotes não-<em>matching</em> (como os oriundos de fora do <em>cluster</em>, por exemplo), estes irão casar com a regra final da <em>chain</em> <code>KUBE-SERVICES</code>, que os redireciona para a <em>chain</em> <code>KUBE-NODEPORTS</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># iptables -vn -t nat -L KUBE-SERVICES | grep ':8880$\|KUBE-NODEPORTS' | grep -v 'MARK'</strong>
    0     0 KUBE-SVC-3H37ZQYOAV4SUDJJ  tcp  --  *      *       0.0.0.0/0            10.104.146.74        /* default/proxy-node:proxy-node cluster IP */ tcp dpt:8880
   19  1140 KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes service nodeports; NOTE: this must be the last rule in this chain */ ADDRTYPE match dst-type LOCAL</pre>
</div>
</div>
<div class="paragraph">
<p>Como esperado, a combinação IP/porta <code>10.104.146.74:8880</code> é exatamente a que se encontra assinalada ao serviço <code>proxy-node</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get svc proxy-node</strong>
NAME         TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
proxy-node   NodePort   10.104.146.74   &lt;none&gt;        8880:30880/TCP   61s</pre>
</div>
</div>
<div class="paragraph">
<p>E o tráfego externo? Ele é redirecionado para a <em>chain</em> <code>KUBE-NODEPORTS</code>, que tem o seguinte conteúdo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># iptables -vn -t nat -L KUBE-NODEPORTS | grep ':30880$' | grep -v 'MARK'</strong>
    1    60 KUBE-EXT-3H37ZQYOAV4SUDJJ  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/proxy-node:proxy-node */ tcp dpt:30880</pre>
</div>
</div>
<div class="paragraph">
<p>Portanto, pacotes com destino a <strong>qualquer</strong> endereço IP e porta <code>30880</code> serão enviados para a <em>chain</em> <code>KUBE-EXT-3H37ZQYOAV4SUDJJ</code>. E o que essa <em>chain</em> faz?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># iptables -vn -t nat -L KUBE-EXT-3H37ZQYOAV4SUDJJ | grep -v 'MARK'</strong>
Chain KUBE-EXT-3H37ZQYOAV4SUDJJ (1 references)
 pkts bytes target     prot opt in     out     source               destination
    1    60 KUBE-SVC-3H37ZQYOAV4SUDJJ  all  --  *      *       0.0.0.0/0            0.0.0.0/0</pre>
</div>
</div>
<div class="paragraph">
<p>Os pacotes são redirecionados para a <em>chain</em> <code>KUBE-SVC-3H37ZQYOAV4SUDJJ</code>. Ora, esta é a mesma <em>chain</em> vista na regra para tráfego interno na <em>chain</em> <code>KUBE-SERVICES</code>! Veja seu conteúdo abaixo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># iptables -vn -t nat -L KUBE-SVC-3H37ZQYOAV4SUDJJ | grep -v 'MARK'</strong>
Chain KUBE-SVC-3H37ZQYOAV4SUDJJ (2 references)
 pkts bytes target     prot opt in     out     source               destination
    1    60 KUBE-SEP-BKZVPG34LTLT4QNK  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/proxy-node:proxy-node -&gt; 10.41.181.147:80 */</pre>
</div>
</div>
<div class="paragraph">
<p>Assim como antes, ela simplesmente redireciona todo o tráfego para a <em>chain</em> <code>KUBE-SEP-BKZVPG34LTLT4QNK</code>. Esta, por sua vez&#8230;&#8203;</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># iptables -vn -t nat -L KUBE-SEP-BKZVPG34LTLT4QNK | grep -v 'MARK'</strong>
Chain KUBE-SEP-BKZVPG34LTLT4QNK (1 references)
 pkts bytes target     prot opt in     out     source               destination
    1    60 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/proxy-node:proxy-node */ tcp to:10.41.181.147:80</pre>
</div>
</div>
<div class="paragraph">
<p>É uma regra DNAT que reescreve IP e porta de destino com a combinação do pod <code>proxy</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get pod proxy -o custom-columns=NAME:.metadata.name,IPADDR:.status.podIP</strong>
NAME    IPADDR
proxy   10.41.181.147</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Antes de prosseguir, remova os objetos criados durante esta atividade:</p>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete pod --all ; kubectl delete svc -l provider!=kubernetes</strong>
pod "curl" deleted
pod "proxy" deleted
service "proxy-node" deleted</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_5_coredns">5) CoreDNS</h3>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Identifique em que namespace, e quais são, os pods utilizados para resolução de nomes dentro do <em>cluster</em>.</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Já vimos esses pods algumas vezes até aqui no curso: eles pertencem ao serviço CoreDNS.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system get pod -l k8s-app=kube-dns</strong>
NAME                      READY   STATUS    RESTARTS   AGE
coredns-f9fd979d6-b5skj   1/1     Running   0          2d2h
coredns-f9fd979d6-zkm6b   1/1     Running   0          2d2h</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Qual é o serviço a ser utilizado para acessar o CoreDNS? Qual endereço IP deve ser configurado para resolução DNS nos pods?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Para descobrir isso, basta listar os serviços existentes no namespace <code>kube-proxy</code>. Veja:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system get svc kube-dns</strong>
NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
kube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53/UDP,53/TCP,9153/TCP   2d2h</pre>
</div>
</div>
<div class="paragraph">
<p>O endereço IP a ser utilizado é, portanto, <code>10.96.0.10</code>.</p>
</div>
</div>
</details>
</li>
<li>
<p>Em qual arquivo deve ser inserida a configuração DNS nos pods do <em>cluster</em>? Verifique sua resposta criando um pod-exemplo.</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Em geral, as configurações de servidor DNS em ambientes Linux ficam no arquivo <code>/etc/resolv.conf</code>. Podemos lançar um pod efêmero com o comando que se segue e verificar esse fato.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl run temp --image=busybox --rm --tty --restart=Never -i -- /bin/sh</strong>
If you don't see a command prompt, try pressing enter.</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ # cat /etc/resolv.conf</strong>
nameserver 10.96.0.10
search default.svc.cluster.local svc.cluster.local cluster.local
options ndots:5</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ # exit</strong>
pod "temp" deleted</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Como esse endereço IP foi adicionado automaticamente ao pod em questão? Revise o arquivo de configuração <code>/var/lib/kubelet/config.yaml</code> e determine o motivo.</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>A opção <code>clusterDNS</code> define essa configuração, como visto abaixo.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># grep clusterDNS /var/lib/kubelet/config.yaml -A1</strong>
clusterDNS:
- 10.96.0.10</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Onde está localizado o arquivo de configuração do CoreDNS? Determine a forma com a qual esse arquivo de configuração é lido pelos pods do deployment.</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vamos analisar o deployment do CoreDNS. Veja o valor da opção <code>-conf</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system describe deploy coredns | grep '\-conf' -A1</strong>
      -conf
      /etc/coredns/Corefile</pre>
</div>
</div>
<div class="paragraph">
<p>O diretório <code>/etc/coredns</code> é, por sua vez, montado a partir de um objeto com o nome <code>config-volume</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system describe deploy coredns | grep 'Mounts' -A1</strong>
    Mounts:
      /etc/coredns from config-volume (ro)</pre>
</div>
</div>
<div class="paragraph">
<p>E este, em última instância, é um ConfigMap de nome <code>coredns</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system describe deploy coredns | grep 'Volumes' -A3</strong>
  Volumes:
   config-volume:
    Type:               ConfigMap (a volume populated by a ConfigMap)
    Name:               coredns</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Analise o conteúdo do arquivo de configuração do CoreDNS, e responda: qual é o domínio-raiz controlado pelo serviço?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Basta verificar o conteúdo do ConfigMap em questão, buscando a linha de invocação do <em>plugin</em> <code>kubernetes</code>. Como já vimos antes no curso, o domínio-raiz do <em>cluster</em> é <code>cluster.local</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n kube-system describe cm coredns | grep 'kubernetes'</strong>
    kubernetes cluster.local in-addr.arpa ip6.arpa {</pre>
</div>
</div>
<div class="paragraph">
<p>Mais detalhes de configuração do CoreDNS e aspectos interessantes podem ser vistos neste link, que explora o tema a fundo: <a href="https://blog.opstree.com/2020/06/16/a-closer-look-at-coredns/" class="bare">https://blog.opstree.com/2020/06/16/a-closer-look-at-coredns/</a> .</p>
</div>
</div>
</details>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_6_ingress">6) Ingress</h3>
<div class="paragraph">
<p>O objeto Ingress expõe requisições HTTP e HTTPS vindas de fora do <em>cluster</em> para serviços internos ao <em>cluster</em>. O roteamento de tráfego é controlado através de regras definidas dentro do recurso Ingress.</p>
</div>
<div class="paragraph">
<p>O Ingress pode ser configurado para prover diversas funcionalidades para serviços, como: URLs externamente acessíveis, balanceamento de carga, terminação SSL/TLS e <em>name-based virtualhosting</em>. O <em>Ingress Controller</em> é responsável por cumprir os requisitos do objeto Ingress, embora também seja possível configurar roteadores de borda ou <em>frontends</em> adicionais para auxiliar o tratamento de tráfego.</p>
</div>
<div class="paragraph">
<p>O Ingress não pode ser utilizado para expor outras portas ou protocolos. Caso se deseje expor outros serviços, que não sejam HTTP ou HTTPS, deve-se utilizar serviços do tipo <code>NodePort</code> ou <code>LoadBalancer</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_6_1_ingress_controller">6.1) Ingress Controller</h3>
<div class="paragraph">
<p>O primeiro passo é, naturalmente, criar o <em>Ingress Controller</em>. Esse recurso é necessário para que os requerimentos de objetos Ingress sejam satisfeitos.</p>
</div>
<div class="paragraph">
<p><em>Ingress Controllers</em> são documentados em <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/" class="bare">https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/</a> . Como visualizado na página em questão, os <em>controllers</em> <code>AWS</code>, GCE` e <code>nginx</code> são internamente suportados e mantidos pelo projeto Kubernetes, embora diversos outros possam ser utilizados.</p>
</div>
<div class="paragraph">
<p>Nesta atividade iremos implementar e configurar o <em>Ingress Controller</em> <code>nginx</code>.</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Faça o deployment do <em>Ingress Controller</em> <code>nginx</code> no <em>cluster</em>. Siga as instruções para <em>clusters</em> do tipo <em>bare-metal</em> disponíveis em <a href="https://kubernetes.github.io/ingress-nginx/deploy/" class="bare">https://kubernetes.github.io/ingress-nginx/deploy/</a>.</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>As instruções, felizmente, são bastante diretas. Basta executar o comando:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.7.1/deploy/static/provider/cloud/deploy.yaml</strong>
namespace/ingress-nginx created
serviceaccount/ingress-nginx created
serviceaccount/ingress-nginx-admission created
role.rbac.authorization.k8s.io/ingress-nginx created
role.rbac.authorization.k8s.io/ingress-nginx-admission created
clusterrole.rbac.authorization.k8s.io/ingress-nginx created
clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created
rolebinding.rbac.authorization.k8s.io/ingress-nginx created
rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created
clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created
clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created
configmap/ingress-nginx-controller created
service/ingress-nginx-controller created
service/ingress-nginx-controller-admission created
deployment.apps/ingress-nginx-controller created
job.batch/ingress-nginx-admission-create created
job.batch/ingress-nginx-admission-patch created
ingressclass.networking.k8s.io/nginx created
validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Vários recursos foram criados no <em>cluster</em> a partir da execução do comando anterior. Em que namespace está o deployment responsável por implementar o <em>Ingress Controller</em>? Qual é o nome desse deployment?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Visualizando o arquivo YAML utilizado para a invocação do comando, observa-se que o namespace criado é o <code>ingress-nginx</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl get ns ingress-nginx</strong>
NAME            STATUS   AGE
ingress-nginx   Active   5m8s</pre>
</div>
</div>
<div class="paragraph">
<p>O deployment, por sua vez, é denominado <code>ingress-nginx-controller</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n ingress-nginx get deploy ingress-nginx-controller</strong>
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
ingress-nginx-controller   1/1     1            1           5m25s</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Onde é armazenada a configuração do <code>ingress-nginx-controller</code>? Qual o conteúdo desse recurso, no momento?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Visualizando o deployment, sua configuração é definida através da opção <code>--configmap</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n ingress-nginx describe deploy ingress-nginx-controller | grep 'configmap'</strong>
      --configmap=$(POD_NAMESPACE)/ingress-nginx-controller</pre>
</div>
</div>
<div class="paragraph">
<p>De forma nada surpreendente, trata-se de um ConfigMap localizado no namespace <code>ingress-nginx</code>, com o nome <code>ingress-nginx-controller</code>. Veja seu conteúdo, abaixo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n ingress-nginx describe cm ingress-nginx-controller</strong>
Name:         ingress-nginx-controller
Namespace:    ingress-nginx
Labels:       app.kubernetes.io/component=controller
              app.kubernetes.io/instance=ingress-nginx
              app.kubernetes.io/name=ingress-nginx
              app.kubernetes.io/part-of=ingress-nginx
              app.kubernetes.io/version=1.7.1
Annotations:  &lt;none&gt;

Data
===
allow-snippet-annotations:
----
true

BinaryData
===

Events:
  Type    Reason  Age   From                      Message
  ----    ------  ----  ----                      -------
  Normal  CREATE  79s   nginx-ingress-controller  ConfigMap ingress-nginx/ingress-nginx-controller</pre>
</div>
</div>
<div class="paragraph">
<p>Por ora ele se encontra vazio, portanto.</p>
</div>
</div>
</details>
</li>
<li>
<p>Como os clientes externos (i.e. fora do contexto do <em>cluster</em>) conseguem acessar o <code>ingress-nginx-controller</code>? Em quais portas devem ser feitas as requisições para os protocolos HTTP e HTTPS?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>O arquivo YAML invocado originalmente criou um serviço do tipo <code>NodePort</code> para acessar o <em>Ingress Controller</em>. Veja:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n ingress-nginx get svc ingress-nginx-controller</strong>
NAME                       TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)                      AGE
ingress-nginx-controller   LoadBalancer   10.109.187.5   &lt;pending&gt;     80:30542/TCP,443:31102/TCP   4m48s</pre>
</div>
</div>
<div class="paragraph">
<p>As portas a serem utilizadas para fazer requisições aos protocolos HTTP e HTTPS podem ser visualizadas na descrição do serviço em questão.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n ingress-nginx describe svc ingress-nginx-controller | grep 'http\|https'</strong>
Port:                     http  80/TCP
TargetPort:               http/TCP
NodePort:                 http  30542/TCP
Port:                     https  443/TCP
TargetPort:               https/TCP
NodePort:                 https  31102/TCP</pre>
</div>
</div>
</div>
</details>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_6_2_ingress_via_http">6.2) Ingress via HTTP</h3>
<div class="paragraph">
<p>Uma vez criado o <em>Ingress Controller</em> podemos, agora sim, criar objetos Ingress e distribuir o tráfego para diferentes aplicações. Vamos fazer isso.</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Claro, precisamos de aplicações primeiro. Siga os passos abaixo:</p>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>Crie o namespace <code>color</code>.</p>
</li>
<li>
<p>Dentro dele, crie o deployment <code>blue</code> contendo apenas uma réplica usando a imagem <code>fbscarel/myapp-color:blue</code>. Crie também um serviço que exponha esse deployment dentro do contexto do <em>cluster</em> na porta 80.</p>
</li>
<li>
<p>De igual forma, crie o deployment <code>red</code> usando a imagem <code>fbscarel/myapp-color:red</code> com as mesmas características do item anterior (incluindo o serviço).</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Verifique o funcionamento de sua configuração antes de prosseguir.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vamos lá: primeiro, crie o namespace.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl create ns color</strong>
namespace/color created</pre>
</div>
</div>
<div class="paragraph">
<p>Como as configurações dos deployments <code>blue</code> e <code>red</code> são exatamente iguais, iremos fazer um <em>loop</em> <code>for</code> para acelerar o processo.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># COLORS=(blue red); \
  for c in ${COLORS[@]}; do \
  kubectl -n color create deploy ${c} --image=fbscarel/myapp-color:${c} --replicas=1; \
  kubectl -n color create svc clusterip ${c} --tcp=80; \
  done</strong>
deployment.apps/blue created
service/blue created
deployment.apps/red created
service/red created</pre>
</div>
</div>
<div class="paragraph">
<p>Terá funcionado? Vamos ver:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n color get deploy,svc</strong>
NAME                   READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/blue   1/1     1            1           4s
deployment.apps/red    0/1     1            0           4s

NAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/blue   ClusterIP   10.101.159.21   &lt;none&gt;        80/TCP    4s
service/red    ClusterIP   10.96.240.40    &lt;none&gt;        80/TCP    4s</pre>
</div>
</div>
<div class="paragraph">
<p>Para verificar o ambiente, utilizaremos um pod qualquer com o comando <code>curl</code> disponível:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n color run curl --image=curlimages/curl --rm --tty -i -- /bin/sh</strong>
If you don't see a command prompt, try pressing enter.</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ $ curl blue/color</strong>
Hostname: blue-5685d56b75-td4hq ; Color: blue</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong>/ $ curl red/color</strong>
Hostname: red-85bb97b57f-rqzz7 ; Color: red</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Agora, é hora de criar o Ingress. Imagine que queremos acessar a URL <code>color.contorq.com</code>, e dentro desse website as páginas <code>/blue</code> e <code>/red</code> irão apontar para cada um dos deployments realizados no passo anterior.</p>
<div class="paragraph">
<p>Crie o Ingress <code>ingress-color-path</code> dentro do namespace <code>color</code> seguindo as especificações acima. Iremos testá-lo no próximo passo.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Esse paradigma de acesso a aplicação é denominado <em>simple fanout</em> na documentação do Kubernetes, acessível em <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/#simple-fanout" class="bare">https://kubernetes.io/docs/concepts/services-networking/ingress/#simple-fanout</a> . Veja como ficaria o arquivo YAML:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Ingress</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ingress-color-path</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">color</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="na">nginx.ingress.kubernetes.io/rewrite-target</span><span class="pi">:</span> <span class="s">/$2</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ingressClassName</span><span class="pi">:</span> <span class="s2">"</span><span class="s">nginx"</span>
  <span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s">color.contorq.com</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/blue(/|$)(.*)</span>
        <span class="na">pathType</span><span class="pi">:</span> <span class="s">ImplementationSpecific</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">blue</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="m">80</span>
      <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/red(/|$)(.*)</span>
        <span class="na">pathType</span><span class="pi">:</span> <span class="s">ImplementationSpecific</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">red</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="s">80</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Os <em>rewrites</em> acima são utilizados para que caminhos adicionais (por exemplo <code>/color</code>) sejam corretamente repassados às aplicações. Essa configuração é discutida em <a href="https://stackoverflow.com/questions/58453553/kubernetes-ingress-backend-subpath" class="bare">https://stackoverflow.com/questions/58453553/kubernetes-ingress-backend-subpath</a> .</p>
</div>
<div class="paragraph">
<p>Agora, crie o objeto Ingress:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f ingress-color-path.yaml</strong>
ingress.networking.k8s.io/ingress-color-path created</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Como não temos um servidor DNS configurado no ambiente externo, iremos utilizar o arquivo <code>/etc/hosts</code> como um substituto rápido. Edite-o com o comando abaixo:</p>
<div class="literalblock">
<div class="content">
<pre><strong># echo '192.168.68.20 color color.contorq.com' >> /etc/hosts</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Depois, utilize o comando <code>ping</code> para testar a resolução de nomes interna:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ping -c1 color.contorq.com | head -n2</strong>
PING color (192.168.68.20) 56(84) bytes of data.
64 bytes from s2-master-1 (192.168.68.20): icmp_seq=1 ttl=64 time=0.036 ms</pre>
</div>
</div>
</li>
<li>
<p>Agora que a resolução do nome <code>color.contorq.com</code> está configurada&#8201;&#8212;&#8201;ainda que de uma forma bastante improvisada&#8201;&#8212;&#8201;podemos testar o Ingress. Acesse as URLs <code>/blue</code> e <code>/red</code> e verifique o funcionamento de sua configuração.</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vamos retomar a porta a ser utilizada para acessar o <em>Ingress Controller</em> via HTTP, externamente:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n ingress-nginx describe svc ingress-nginx-controller | grep 'http '</strong>
Port:                     http  80/TCP
NodePort:                 http  30542/TCP</pre>
</div>
</div>
<div class="paragraph">
<p>Utilizando essa porta, fazemos uma requisição ao caminho <code>/blue/color</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl http://color.contorq.com:30542/blue/color</strong>
Hostname: blue-57c8888766-t4mv4 ; Color: blue</pre>
</div>
</div>
<div class="paragraph">
<p>E, depois, <code>/red/color</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl http://color.contorq.com:30542/red/color</strong>
Hostname: red-5df8dbd58-gqzgx ; Color: red</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>O que ocorre caso acessemos a URL-base <code>color.contorq.com</code>, sem nenhum caminho adicional informado? Porquê?</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vamos ver:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl -s http://color.contorq.com:30542/ | grep h1</strong>
&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>Isso se deve à indisponibilidade de um <em>default backend</em>. Esse <em>backend</em> é utilizado para tratar quaisquer requisições enviadas para um caminho não tratado ou compreendido pelo <em>ingress controller</em>. Veja, na aba eventos do <code>ingress-color-path</code>, que esse fato é apontado pelo ambiente:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n color describe ingress ingress-color-path | grep Default</strong>
Default backend:  &lt;default&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>Normalmente esse <em>default backend</em> (como documentado em <a href="https://kubernetes.github.io/ingress-nginx/user-guide/default-backend/" class="bare">https://kubernetes.github.io/ingress-nginx/user-guide/default-backend/</a>) oferece dois endpoints: <code>/healthz</code> (código de retorno <code>200</code>) e <code>/</code> (código de retorno <code>404</code>). O <em>default backend</em> é, convencionalmente, uma opção de configuração do <em>ingress controller</em> e não é especificado nos recursos Ingress.</p>
</div>
<div class="paragraph">
<p>Se você quisesse teoricamente fazer com que qualquer requisição não-reconhecida fosse direcionada ao serviço <code>blue</code> no <em>namespace</em> <code>color</code>, você poderia adicionar o excerto abaixo à seção <code>.spec</code> do manifesto de definição do Ingress:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>  defaultBackend:
    service:
      name: blue
      port:
       number: 80</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Ao invés de utilizar os caminhos <code>/blue</code> e <code>/red</code>, fomos instruídos a alterar a configuração do Ingress para servir os recursos através das URLs <code>blue.color.contorq.com</code> e <code>red.color.contorq.com</code>.</p>
<div class="paragraph">
<p>Faça as alterações necessárias no arquivo <code>/etc/hosts</code>. Em seguida, remova o Ingress <code>ingress-color-path</code> e crie um novo, <code>ingress-color-name</code>, que implemente os acessos objetivados.</p>
</div>
<div class="paragraph">
<p>Finalmente, verifique o funcionamento de sua configuração.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Vamos primeiro adicionar os domínios <code>blue.color.contorq.com</code> e <code>red.color.contorq.com</code> ao arquivo <code>/etc/hosts</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># COLORS=(blue red); \
  for c in ${COLORS[@]}; do \
  echo "192.168.68.20 ${c} ${c}.color.contorq.com" >> /etc/hosts
  done</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Depois, vamos testar um deles com o comando <code>ping</code> para verificar seu funcionamento.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ping -c1 blue.color.contorq.com | head -n2</strong>
PING blue (192.168.68.20) 56(84) bytes of data.
64 bytes from s2-master-1 (192.168.68.20): icmp_seq=1 ttl=64 time=0.037 ms</pre>
</div>
</div>
<div class="paragraph">
<p>OK! Agora, removemos o Ingress <code>ingress-color-path</code>.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n color delete ingress ingress-color-path</strong>
ingress.extensions "ingress-color-path" deleted</pre>
</div>
</div>
<div class="paragraph">
<p>O paradigma de acesso solicitado é conhecido como <em>name based virtual hosting</em>, e documentado em <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/#name-based-virtual-hosting" class="bare">https://kubernetes.io/docs/concepts/services-networking/ingress/#name-based-virtual-hosting</a> . Veja como ficaria o arquivo YAML:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Ingress</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ingress-color-name</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">color</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="na">nginx.ingress.kubernetes.io/rewrite-target</span><span class="pi">:</span> <span class="s">/</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ingressClassName</span><span class="pi">:</span> <span class="s2">"</span><span class="s">nginx"</span>
  <span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s">blue.color.contorq.com</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/</span>
        <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">blue</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="m">80</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s">red.color.contorq.com</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/</span>
        <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">red</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="s">80</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Crie o objeto Ingress:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f ingress-color-name.yaml</strong>
ingress.networking.k8s.io/ingress-color-path created</pre>
</div>
</div>
<div class="paragraph">
<p>E teste os acessos às URLs:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl -s http://blue.color.contorq.com:30542/color</strong>
Hostname: blue-5685d56b75-td4hq ; Color: blue</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl -s http://red.color.contorq.com:30542/color</strong>
Hostname: red-85bb97b57f-rqzz7 ; Color: red</pre>
</div>
</div>
</div>
</details>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_6_3_ingress_via_https">6.3) Ingress via HTTPS</h3>
<div class="olist loweralpha">
<ol class="loweralpha">
<li>
<p>Vamos agora incrementar a configuração realizada durante a atividade anterior. Para começar, crie um certificado auto-assinado usando o comando <code>openssl req</code>. Na linha <em>Subject</em>, garanta que os atributos <code>CN</code> e <code>O</code> correspondem ao <em>wildcard</em> <code>*.color.contorq.com</code>.</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>A criação de certificados TLS é documentada em diversos lugares; um deles é o próprio website do <em>Ingress Controller</em> <code>nginx</code>, em <a href="https://kubernetes.github.io/ingress-nginx/user-guide/tls/" class="bare">https://kubernetes.github.io/ingress-nginx/user-guide/tls/</a> . Como visto, pode-se utilizar o comando abaixo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># openssl req -x509 -nodes -days 365 -newkey rsa:4096 -keyout ~/color.key -out color.crt -subj "/CN=&#42;.color.contorq.com/O=&#42;.color.contorq.com"</strong></pre>
</div>
</div>
<div class="paragraph">
<p>Verifique que o certificado e chave privada foram de fato criados:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># ls -1 color.&#42;</strong>
color.crt
color.key</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Crie o secret <code>color-tls</code> utilizando a chave privada e certificado criado no passo anterior. Utilize o tipo <code>tls</code>.</p>
<div class="paragraph">
<p>A seguir, verifique o funcionamento de sua configuração.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>A configuração de um secret TLS e Ingress correspondente é documentada em <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/#tls" class="bare">https://kubernetes.io/docs/concepts/services-networking/ingress/#tls</a> . Pode-se fazê-lo via arquivo YAML, ou diretamente via <code>kubectl create secret</code>, desta forma:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n color create secret tls color-tls --cert ~/color.crt --key ~/color.key</strong>
secret/color-tls created</pre>
</div>
</div>
<div class="paragraph">
<p>Veja seu conteúdo:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n color describe secrets color-tls</strong>
Name:         color-tls
Namespace:    color
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;

Type:  kubernetes.io/tls

Data
===
tls.crt:  1915 bytes
tls.key:  3272 bytes</pre>
</div>
</div>
</div>
</details>
</li>
<li>
<p>Remova o Ingress <code>ingress-color-name</code> e, em seu lugar, crie o Ingress <code>ingress-color-tls</code> que sirva os recursos através das URLs <code>blue.color.contorq.com</code> e <code>red.color.contorq.com</code>.</p>
<div class="paragraph">
<p>Faça com que os clientes que acessem o website em HTTP sejam automaticamente redirecionados para a página em HTTPS, e que o secret criado no passo anterior seja utilizado na cifragem da comunicação.</p>
</div>
<div class="paragraph">
<p>Finalmente, verifique o funcionamento do ambiente.</p>
</div>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="paragraph">
<p>Primeiro, removemos o Ingress.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n color delete ingress ingress-color-name</strong>
ingress.extensions "ingress-color-name" deleted</pre>
</div>
</div>
<div class="paragraph">
<p>Depois, criamos o <code>ingress-color-tls</code> via arquivo YAML, como se segue. A documentação do Kubernetes referenciada no passo anterior contém detalhes sobre o processo de criação do arquivo em questão.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Ingress</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ingress-color-tls</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">color</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="na">nginx.ingress.kubernetes.io/rewrite-target</span><span class="pi">:</span> <span class="s">/</span>
    <span class="na">nginx.ingress.kubernetes.io/ssl-redirect</span><span class="pi">:</span> <span class="s2">"</span><span class="s">true"</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ingressClassName</span><span class="pi">:</span> <span class="s2">"</span><span class="s">nginx"</span>
  <span class="na">tls</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">hosts</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">blue.color.contorq.com</span>
      <span class="pi">-</span> <span class="s">red.color.contorq.com</span>
    <span class="na">secretName</span><span class="pi">:</span> <span class="s">color-tls</span>
  <span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s">blue.color.contorq.com</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/</span>
        <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">blue</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="m">80</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s">red.color.contorq.com</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/</span>
        <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">red</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="s">80</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl apply -f ingress-color-tls.yaml</strong>
ingress.networking.k8s.io/ingress-color-tls created</pre>
</div>
</div>
<div class="paragraph">
<p>Antes de prosseguir, retomemos quais são as portas a utilizar para acessar o <em>Ingress Controller</em> via HTTP e HTTPS.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># kubectl -n ingress-nginx describe svc ingress-nginx-controller | grep 'http \|https '</strong>
Port:                     http  80/TCP
NodePort:                 http  30542/TCP
Port:                     https  443/TCP
NodePort:                 https  31102/TCP</pre>
</div>
</div>
<div class="paragraph">
<p>Vamos começar acessando o serviço via HTTPS.</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl https://blue.color.contorq.com:31102/color</strong>
curl: (60) SSL certificate problem: self signed certificate
More details here: <a href="https://curl.haxx.se/docs/sslcerts.html" class="bare">https://curl.haxx.se/docs/sslcerts.html</a>

curl failed to verify the legitimacy of the server and therefore could not
establish a secure connection to it. To learn more about this situation and
how to fix it, please visit the web page mentioned above.</pre>
</div>
</div>
<div class="paragraph">
<p>O <code>curl</code> retorna um erro, afirmando que não consegue verificar a validade do certificado. Como ele é auto-assinado, esse comportamento é completamente esperado. Consultando a página de manual do comando (<code>man curl</code>), observa-se que as <em>flags</em> <code>--insecure</code> ou <code>-k</code> podem ser utilizadas para remover essa verificação. Aplique-as:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl -sk https://blue.color.contorq.com:31102/color</strong>
Hostname: blue-5685d56b75-td4hq ; Color: blueroot@s2-master-1:~#</pre>
</div>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl -sk https://red.color.contorq.com:31102/color</strong>
Hostname: red-85bb97b57f-rqzz7 ; Color: red</pre>
</div>
</div>
<div class="paragraph">
<p>Perfeito, o acesso via HTTPS funcionou como esperado. E quanto ao protocolo HTTP?</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl -s http://blue.color.contorq.com:30542/color | grep h1</strong>
&lt;center&gt;&lt;h1&gt;308 Permanent Redirect&lt;/h1&gt;&lt;/center&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>Temos um redirecionamento, como configurado. Na página de manual do <code>curl</code>, as <em>flags</em> <code>--location</code> ou <code>-L</code> devem ser utilizadas para seguir redirecionamentos automaticamente. Vamos ver:</p>
</div>
<div class="literalblock">
<div class="content">
<pre><strong># curl -L http://blue.color.contorq.com:30542/color</strong>
curl: (7) Failed to connect to blue.color.contorq.com port 443: Connection refused</pre>
</div>
</div>
<div class="paragraph">
<p>No caso, o <em>redirect</em> nos envia à porta 443, porta-padrão do procolo HTTPS. Para alterar a porta do <em>redirect</em>, seria interessante portanto configurar um <em>proxy</em> reverso à frente do <em>Ingress Controller</em>, garantindo que os clientes consigam acessar os serviços nas portas esperadas, TCP/80 para HTTP e TCP/443 para HTTPS.</p>
</div>
</div>
</details>
</li>
<li>
<p>Antes de prosseguir, remova os recursos criados durante esta atividade.</p>
<details>
<summary class="title">Visualizar resposta</summary>
<div class="content">
<div class="literalblock">
<div class="content">
<pre><strong># kubectl delete ns color ; kubectl delete ns ingress-nginx</strong>
namespace "color" deleted
namespace "ingress-nginx" deleted</pre>
</div>
</div>
</div>
</details>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Nota"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Como visto, as configurações realizadas para o funcionamento do Ingress nesta atividade atenderam nossas expectativas, mas dependem de alguns recursos externos para serem utilizadas de forma plena em um ambiente de produção real. Como mínimo, recomenda-se que haja:</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>Um servidor DNS externo resolvendo os <em>hostnames</em> a serem servidos pelo <em>cluster</em> Kubernetes (como <code>blue.color.contorq.com</code> ou <code>red.color.contorq.com</code>), de forma que não seja necessário configurar o arquivo <code>/etc/hosts</code> manualmente.</p>
</li>
<li>
<p>Um balanceador de carga ou <em>proxy</em> reverso externo que receba conexões dos clientes nas portas 80 e 443 e as redirecione para os <code>NodePorts</code> configurados no <em>Ingress Controller</em> do <em>cluster</em> Kubernetes.</p>
</li>
<li>
<p>Um ou mais certificados TLS válidos que permitam que clientes conectem-se com segurança (i.e. conseguindo validar a cadeia de certificação completa, até a CA raiz) aos serviços publicados pelo <em>cluster</em>.</p>
</li>
</ul>
</div>
</div>
</div>
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Aviso"></i>
</td>
<td class="content">
<div class="paragraph">
<p><strong>ENTREGA DA TAREFA</strong></p>
</div>
<div class="paragraph">
<p>Para que seja considerada entregue você deve anexar a esta atividade no AVA uma imagem (nos formatos .png ou .jpg) do terminal mostrando a saída do comando <code>curl</code> ao contatar o endereço <code>blue.color.contorq.com</code> via HTTPS.</p>
</div>
<div class="paragraph">
<p>Utilize como referência a saída de comando mostrada na atividade 8.6.3 (c) deste roteiro.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Última atualização 2023-05-06 16:36:35 -0300
</div>
</div>
</body>
</html>
